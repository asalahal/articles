RESEARCH ARTICLE
Detection of Patients at Risk of Multidrug-
Resistant Enterobacteriaceae Infection Using
                                                                                                                                                                                   Citation: Gouareb R, Bornet A,
Graph Neural Networks: A Retrospective Study                                                                                                                                       Proios D,  Pereira SG, Teodoro D.
                                                                                                                                                                                   Detection of Patients at
Racha  Gouareb      1*†                                                , Alban   Bornet     1,2*†                                                                     , Dimitrios  Proios      1,2*                                          , Risk of Multidrug-Resistant
                                                         *                   , and Douglas  T                    2,4*                                                              Enterobacteriaceae Infection
Sónia Gonçalves  Pereira      3                                                                 eodoro             1,                                                              Using Graph Neural Networks: A
                                                                                                                                                                                   Retrospective Study. Health Data Sci.
1Department of Radiology and Medical Informatics, University of Geneva, Geneva, Switzerland. 2HES-                                                                                 2023;3:Article 0099. https://doi.
SO University of Applied Arts Sciences and Arts of Western Switzerland, Geneva, Switzerland. 3Center                                                                               org/10.34133/hds.0099
for Innovative Care and Health Technology, Polytechnic of Leiria, Leiria, Portugal. 4Swiss Institute of                                                                            Submitted 3 January 2023
Bioinformatics, Lausanne, Switzerland.                                                                                                                                             Accepted 23 October 2023
                                                                                                                                                                                   Published 20 November 2023
*Address correspondence to: racha.gouareb@unige.ch (R.G); alban.bornet@unige.ch (A.B.); dimitrios.                                                                                 Copyright © 2023 Racha Gouareb
proios@unige.ch (D.P.); sonia.pereira@ipleiria.pt (S.G.P.); douglas.teodoro@unige.ch (    D  .T.    )                                                                              et al.  Exclusive licensee Peking
†These authors contributed equally to this work.                                                                                                                                   University Health Science Center. No
                                                                                                                                                                                   claim to original U.S. Government
                                                                                                                                                                                   Works. Distributed under a Creative
Background:                                                                                                           While Enterobacteriaceae bacteria are commonly found in the healthy human gut, their Commons Attribution License 4.0
colonization of other body parts can potentially evolve into serious infections and health threats.                                                                                (CC BY 4.0).
We investigate a graph-based machine learning model to predict risks of inpatient colonization by
multidrug-resistant (MDR) Enterobacteriaceae. Methods:                                                                                                                                          Colonization prediction was defined as a
binary task, where the goal is to predict whether a patient is colonized by MDR Enterobacteriaceae
in an undesirable body part during their hospital stay. To capture topological features, interactions
among patients and healthcare workers were modeled using a graph structure, where patients are
described by nodes and their interactions are described by edges. Then, a graph neural network
(GNN) model was trained to learn colonization patterns from the patient network enriched with
clinical and spatiotemporal features. Results:                                                                                         The GNN model achieves performance between 0.91
and 0.96 area under the receiver operating characteristic curve (AUROC) when trained in inductive and
transductive settings, respectively, up to 8% above a logistic regression baseline (0.88). Comparing
network topologies, the configuration considering ward-related edges (0.91 inductive, 0.96 transductive)
outperforms the configurations considering caregiver-related edges (0.88, 0.89) and both types of
edges (0.90, 0.94). For the top 3 most prevalent MDR Enterobacteriaceae, the AUROC varies from 0.94
for    Citrobacter freundii up to 0.98 for Enterobacter cloacae using the best-performing GNN model.
Conclusion:                                                                                                                                                                           Topological features via graph modeling improve the performance of machine learning
models for Enterobacteriaceae colonization prediction. GNNs could be used to support infection
prevention and control programs to detect patients at risk of colonization by MDR Enterobacteriaceae
and other bacteria families.
Introduction                                                                                                              infections have augmented drastically over the last 2 decades,
                                                                                                                          especially with the rise of carbapenemase-producing Entero-
Healthcare-associated infection (HAI) is a severe health problem                                                          bacteriaceae [6]. These pathogens are able to resist not only the
for patients, health professionals, and visitors in a healthcare facil-                                                   action of all available beta-lactams (except aztreonam), but also
ity [1,2]. The World Health Organization estimates that 1 in ever y                                                       other available antimicrobial classes like fluoroquinolones and
10 patients develops an HAI [3], and in US hospitals alone, the                                                           aminoglycosides, leaving physicians with few treatment options
Centers for Disease Control and Prevention estimate that HAIs                                                             [7]. This leads to more expensive treatments, longer hospital
account for 1.7 million infections and 99,000 associated deaths                                                           stays, increased risk of complication, and higher risk of death [8].
each year [4]. Among these infections, more than one-third are                                                                 The continuous rise of these pathogens in healthcare set-
caused by Enterobacteriaceae [5], a family of bacteria that includes                                                      tings is multifactorial, main contributors being their ability
the most prevalent human pathogenic species and leading causes                                                            to spread and persist in the environment and asymptomati-
of nosocomial infections, such as Escherichia coli                         ,   Salmonella                                 cally in patients, as well as healthcare workers and utilities [9].
enterica, and Klebsiella pneumoniae                                                     . Given that these infections     The risk of colonization, subsequent infection, and mortality
are acquired in environments under high antimicrobial pressure,                                                           due to Entero  bacteriaceae increases exponentially with age,
they are often caused by antimicrobial-resistant (AMR) and                                                                health histor y, and length of hospital stay [10]. Colonization
multidrug-                                                                 resistant (MDR) bacteria. MDR Enterobacteriaceae can be defined as the asymptomatic presence of a pathogen
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1

in the human body. It is the first step toward an overt disease                                             •                            We design GNN models for colonization prediction that
of the colonized patient, with more or less severity, and also                                                 learn transmission network patterns from spatiotempo-
one of the main contributors to infection outbreaks in health        -                                         ral and patient data. Different network configurations
care settings [11]. Indeed, some studies showed that between                                                   and transmission paths are proposed and evaluated.
36% and 39% of patients colonized by AMR Enterobacteriaceae                                                 •      We evaluate our model against classic state-of-the-art
develop a subsequent infection [12,13]. Asymptomatic colo-                                                     machine learning baselines and show that it achieves
nizations, especially by MDR bacteria, pose a prominent pub         -                                          superior performance, both when baseline models access
lic health problem as the pathogen that the colonized patient                                                  network information via node2vec [34] embeddings, or
carries can inadvertently be transmitted to other patients, who                                                not. We also conduct an explainability study to demon-
can become infected, with increased risk of complications,                                                     strate the capacity of the model to automatically identify
and even death [6]. Infection prevention and control (IPC)                                                     features associated with colonization risk factors.
programs provide critical measures for preventing disease                                                   •     There have been many studies investigating HAI pre-
transmission in healthcare settings, with the potential to lower                                               diction. To the best of our knowledge, this is the first
HAI rates by at least 30% [14], which is sometimes the only                                                    attempt to explore the problem of predicting risks of
solution to prevent and avoid these MDR colonizations and                                                      Enterobacteriaceae colonization for undesirable body
infections.                                                                                                    parts using GNNs and provide data-driven hypothesis
    Leveraging the availability of large-scale healthcare data                                                 for transmission.
[15–17], routinely collected and stored in electronic health
records (EHRs), machine learning models have been proposed
for the early detection of patients at risk of infection and to                                       Methods
support IPC programs [18–22]. Classic machine learning meth   -
ods, such as decision trees and random forest, have demon-                                            Study design and data sources
strated good performance to predict patients at risk of HAI                                           To train and evaluate our colonization risk prediction models,
[23–26]. For methicillin-resistant Staphylococcus aureus                       [23]                   we used laboratory, clinical, and administrative data from
and Clostridioides difficile [26], these algorithms were shown to                                     patients who stayed in critical care units of the Beth Israel
provide warnings as early as 5 days before diagnosis. Machine                                         Deaconess Medical Center (Massachusetts, USA). These data
learning methods for colonization prediction were also explored                                       were recorded between 2001 and 2012 and made publicly avail-
in very recent studies [27–29]. Tree-based machine learning                                           able through the MIMIC-III dataset [33]. MIMIC-III is a freely
methods, such as decision trees, random forest, and extreme                                           available and deidentified healthcare dataset that consists of 26
gradient boosting, achieved sensitivity and specificity above 80%                                     tables and includes static and dynamic patient information,
for detecting MDR species from different pathogenic families                                          such as demographics, medical histor y and records, clinical
[28], while the use of spatiotemporal features to identify patients                                   measures, laboratory tests, and interventions. The database
colonized by vancomycin-resistant Enterococcus                    resulted in area                    contains data from 46,520 unique patients aged 16 years or older
under the receiver operating characteristic curve (AUROC)                                             and associated to 58,976 admissions. Patients can be admitted
performance above 88% [27].                                                                           to the hospital more than once and moved between 50 different
    While classic machine learning models and hand-crafted                                            wards and 7 care units during their stays. Additionally, activities
features might show effective results in limited use cases,                                           from 7,567 unique healthcare workers—a nurse or a medical
they often fail to generalize to large-scale and longitudinal                                         doctor— are           recorded.
EHR data [30,31]. Another limitation of previous approaches                                               In the MIMIC-III dataset, 10% of inpatients had a positive
for Enterobacteriaceae colonization prediction is that key                                            result for Enterobacteriaceae screen. In total, 14 different bac-
interactions between patients and healthcare workers are                                              terial species of the Enterobacteriaceae family were found from
neglected, hindering their application to complex care net-                                           a total of 30 unique specimen types collected from inpatients.
works. To address these gaps, we propose a deep-learning                                              Figure 1 shows their distribution for different sample types (Fig.
approach based on a graph neural network (GNN) architec                -                              1, left) and different resistant profiles (Fig. 1, right). E. coli was
ture [32]. This approach aims to incorporate interactions                                             the most frequently found species in positive cultures (50%),
between patients and healthcare workers, inside and outside                                           while    Citrobacter amalonaticus and Salmonella enterica         (not
the wards, as well as other clinical and spatiotemporal fea-                                          shown) were rarely found. A bacterial isolate was considered
tures, to predict the risk of Enterobacteriaceae colonization                                         AMR if it showed resistance to at least one agent in only 1 or 2
for inpatients. Our models were trained and evaluated using                                           antimicrobial categories, and MDR if resistant to at least one
the Medical Information Mart for Intensive Care (MIMIC-                                               agent in 3 or more antimicrobial categories [35]. Other wise, it
III) dataset [33] and compared with classic machine learning                                          was classified as AMS. As shown in Fig. 1, Citrobacter koseri,
baselines. Interestingly, GNN models provide stronger pre-                                            E. coli, and K. pneumoniae                                     were the species with the highest
dictive performance for early detection of antimicrobi-                                               levels of resistance (>50%). Both E. coli and K. pneumoniae
al-sensitive (AMS), AMR, and MDR Enterobacteriaceae,                                                  showed MDR profiles in more than 25% of cases.
compared to baseline models trained with or without patient                                                The training and evaluation dataset used in this study was
network information. Our main contributions can be sum-                                               created using the cohort selection criteria described in Fig. 2.
marized as follows:                                                                                   The Microbiology Events table from MIMIC-III was used to
     •  We propose a graph-based colonization model that                                              detect positively colonized patients. The table contains bacterial
         considers spatiotemporal features in addition to demo-                                       identification and antimicrobial testing results and consists
         graphic and clinical condition. To avoid adding biases                                       of 631,726 events related to 46,520 patients. A list of Entero-
         to the model due to information leakage, we do not use                                       bacteriaceae species was selected using the National Center for
         antimicrobial information.                                                                   Biotechnolog y Information terminolog y [36] and used to select
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2

Fig. 1. Frequency of positive culture and resistant profile for each Enterobacteriaceae family member. Species with less than 5 positive cultures are not shown. Bal, bronchoalveolar
lavage.
the microbiology events of patients colonized by Entero-                                                          death and the discharge status of the patient, were eliminated.
bacteriaceae. This first step resulted in 109,318 events related                                                  The selection converged to 2 types of features: (a) spatiotem-
to 4,868 colonized patients. Then, a list of abnormal specimens                                                   poral features (current and previous ward, current and previous
(or uncommon body parts) where these species were found                                                           care unit, length of stay in each ward and in the hospital) and
was identified by 2 clinical microbiologist experts and cate-                                                     (b) patient features (gender and diagnosis at admission). To
gorized into 6 specimen categories: blood, gastric-related,                                                       complement this set, we computed 3 new features from the
respirator y, skin, tissue, and urine. This list defined the set of                                               data: the number of colonized patients, the total number of
positive events that were relevant to our study, i.e., the pres-                                                  patients per ward, and the colonization pressure [37]. The latter
ence of Enterobacteriaceae in abnormal body parts, resulting                                                      was calculated as the ratio of colonized and the total number
in 107,313 microbiolog y events and 4,838 colonized patients.                                                     of patients in a ward per day. Finally, the features were normal-
The Admissions table details hospitalizations of ever y patient                                                   ized using the robust scaler method of scikit-learn [38], version
in the database, and was used to define the remaining non-                                                        1.1.2. Table 1 shows the statistics of the resulting dataset.
colonized patients. Among all admitted patients, the ones
that were not found in the filtered Microbiolog y Events table,                                                   Colonization network model
in addition to those with Enterobacteriaceae in regular speci-                                                    We propose a homogeneous graph to model interactions
mens (i.e., stool samples), were considered non-colonized.                                                        between patients and healthcare workers. A graph can be defined
Lastly, the table Transfers,               which contains patient location                                        as G = (         V,     E), where V                            = v1, …, v                                                                  ∣V∣ denotes a set of nodes and
information and their transfers between wards, was used to                                                        E denotes a set of edges connecting pairs of nodes v                                                          i, vj ∈                  V. In
assign patients to wards. The final dataset contained 46,520                                                      our case, a node represents a patient in a ward and edges repre-
unique patients from 58,976 admissions, and a total of 274,316                                                    sent potential connections between patients, either via contacts
patient–ward instances. If, during a stay in a ward, there was                                                    with the same healthcare worker or via a common location
no positive abnormal Enterobacteriaceae culture for a patient,                                                    within the hospital. As shown in Fig. 3A, we considered 3 net-
the patient–ward instance was labeled as non-colonized; oth               -                                       work configurations: (a) in-ward links (left), where 2 patients
erwise, it was labeled as colonized. This resulted in 7,216                                                       are linked only if they stay in the same ward at the same time;
positive Enterobacteriaceae colonizations (2.6%) and 267,100                                                      (b) out-ward links (middle), where 2 patients are connected only
negative specimens (97.4%). The dataset was randomly divided                                                      if they are visited by the same healthcare worker on the same
into train (60%), dev (20%), and test (20%) splits to train model                                                 day ; and (c) all links (right), where both ward and healthcare
parameters, optimize model hyper parameters, and evaluate                                                         worker links are considered. Nodes represent a patient in a ward
model performance, respectively. Each split contained 2.5% to                                                     and their features are created using the selected set of features
3% colonized patients.                                                                                            described in the previous subsection. For each patient transfer,
                                                                                                                  a new node is added to the graph and edges are set following
Feature selection and data pre-processing                                                                         the network configuration (i.e., in-ward, out-ward, or all links).
The feature selection process was performed iteratively. The
MIMIC-III dataset was first analyzed to pre-identify the set of                                                   GNN architecture
features we considered relevant to the colonization risk predic-                                                  GNN [32,39–41] is an elegant deep learning architecture for
tion problem. Then, based on model performance computed                                                           modeling graph-like data structures and learning topological
with the dev set, less important features, such as the time of                                                    features, i.e., in our case, properties of the transmission network.
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   3

                                                                                                            networks (GAT) [42], and GraphSAGE [43]. These approaches
                                                                                                            use various graph feature aggregation and data sampling strat-
                                                                                                            egies to learn dense representations of graph components (i.e.,
                                                                                                            nodes and edges), often called embeddings, that can be later
                                                                                                            used in downstream prediction tasks, such as node classifica-
                                                                                                            tion. Each layer of a GNN aggregates a subset of the nodes of
                                                                                                            the previous layer to generate an updated feature vector, for
                                                                                                            each node. GCN layers average the features of neighboring
                                                                                                            nodes in the previous layer, akin to convolutional neural net-
                                                                                                            works. They can efficiently capture local graph structures and
                                                                                                            scale to large graphs. GAT layers extend GCNs by adding an
                                                                                                            attention mechanism. Instead of treating all neighbors equally
                                                                                                            as in GCN layers, GAT dynamically computes the weights of
                                                                                                            the node aggregation process, based on node features. They are
                                                                                                            hence able to capture the local structure of the graph in a more
                                                                                                            nuanced way. GraphSAGE layers generate embeddings by sam-
                                                                                                            pling and aggregating features from a node's local neighbor-
                                                                                                            hood. The advantage of GraphSAGE is that it can learn from
                                                                                                            ver y large graphs and generate embeddings for unseen nodes,
                                                                                                            allowing the network to generalize to larger datasets.
                                                                                                                 In our experiments, we let the type (GCN, GAT, and
                                                                                                            GraphSAGE), number (from 2 to 5), and hidden dimension (16,
                                                                                                            32, 64, 128, and 256) of the GNN layers as hyper- parameters. A
                                                                                                            high-level view of the graph-based prediction pipeline is shown
                                                                                                            in Fig. 3. Using laboratory, clinical, and administrative data,
                                                                                                            patient features at the ward level (since a node represents a
                                                                                                            patient in a ward) were extracted and modeled in different net-
                                                                                                            work colonization models (Fig. 3A). The colonization graph
                                                                                                            was fed to the GNN, which performed the node classification
                                                                                                            task. Each GNN layer was followed by a rectified linear unit
                                                                                                            (ReLU) operation and a dropout layer, whose probability was
                                                                                                            used as a hyper-parameter (0.1, 0.2, 0.3, 0.4, and 0.5). Finally,
                                                                                                            each node’s feature vector of the last GNN layer was sent to a
                                                                                                            sigmoid layer for node classification (Fig. 3B). To account for
                                                                                                            data imbalance, we used a weighted focal loss[44]. The weight
                                                                                                            of each sample was set to 1 for non-                                              colonized samples and to
                                                                                                            a hyper-parameter (from 10 to 1,000) for colonized samples.
                                                                                                            Moreover, we tried different data balance scenarios (original
                                                                                                            data, over-sampling of the minority class, and under-sampling
Fig. 2.      Cohort selection criteria. Starting from the Microbiology Events table of MIMIC-               of the majority class). We trained all models for 500 epochs,
III, lab results were filtered for the presence Enterobacteriaceae in unusual body parts                    using the AdamW [45] optimizer with a learning rate that
to define colonized patients. Admissions and Transfers tables were used to identify                         was set as a hyper-parameter (from 0.001 to 1.0). We had
the remaining patients and to label all patients.                                                           different conditions defined by the type of network we used
                                                                                                            as data (all links, ward links only, and caregiver links only),
                                                                                                            the type of settings in which the network was trained and
                                                                                                            evaluated (transductive or inductive), and the type of data
GNNs can learn complex relationships and interdependencies                                                  balance scenario. For each of these conditions, all hyper-
in graph-like data via optimizable transformations on attributes                                            parameters of the GNN model were optimized using Optuna
(nodes, edges, etc.) that preser ve graph symmetries (i.e., per-                                            [46], sampling hyper- parameters for 100 trials with the
mutation invariance/equivariance). Hence, in theory, GNNs                                                   TPESampler [47] algorithm to maximize AUROC, computed
can make more informed predictions about entities in a net-                                                 with the dev set. The best set of hyper-parameters identified
work and their interactions, as compared to models that con-                                                for each condition is available at https://github.com/ds4dh/
sider entities in isolation. One distinct advantage of graph-based                                          hai_project/tree/master/models/gnn.
techniques is their ability to perform inductive and transductive
learning. In inductive learning, models learn to generalize to                                              Statistical analysis
unseen nodes or graphs, whereas the transductive approach                                                   To evaluate the performance of the colonization risk prediction
includes test nodes (not including true labels) in the graph                                                models, we computed metrics typically used in medical con-
during training. The disadvantage of the transductive setting                                               texts, where it is crucial to understand both the ability to cor-
is that the model must be retrained for each new instance.                                                  rectly identify positive and negative cases: sensitivity, specificity,
    To solve graph representation learning tasks, different GNN                                             and AUROC. The GNN models were compared to classic
network architectures and algorithms have been proposed, such                                               machine learning baselines: k-nearest neighbors (k-NN) [48],
as graph convolutional network (GCN) [32], graph attention                                                  logistic regression [49], random forest [50], and CatB oost [51].
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  4

                      Table 1. Statistics of the cohort used for model training and evaluation
                      Model                                                                                                                                                                                                                                                      Data balance                                                                                                               Setting                                                                                                                                                  Links                                                                                                 Accuracy (%)                                                              Sensitivity (%)                                                              Specificity (%)                                                                                                   AUROC (%) (95% CI)
                      Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                 82.37                                                                                                                                                                                                                            74  . 74                                                                                                                                                                                                                                  82.58                                                                                                                                                                                                                                              87.92
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          (87.17–88.70)
                      Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                       89.19                                                                                                                                                                                                                         63.43                                                                                                                                                                                                                                 89.89                                                                                                                                                                                                                                                88.11
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (87.41–88.96)
                      Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                             Transductive                                                                             In-ward                                                                                                                                                     80.77                                                                                                                                                                                                                         78.42                                                                                                                                                                                                                                80.84                                                                                                                                                                                                                                         88.59
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (87.93–89.32)
                      k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                                                                                                                                      -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                  80.15                                                                                                                                                                                                                         82.10                                                                                                                                                                                                                                   80.10                                                                                                                                                                                                                                              90.14
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (89.35–90.83)
                      k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                                                          Inductive                                                                                                            In-ward                                                                                                                                                   86.23                                                                                                                                                                                                                         6    7.     5     9                                                                                                                                                                                                                                      8 6.73                                                                                                                                                                                                                                                 87.66
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (86.93–88.52)
                      k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                           Transductive                                                                             In-ward                                                                                                                                                     72.46                                                                                                                                                                                                                             81.61                                                                                                                                                                                                                                        72.22                                                                                                                                                                                                                                             86.43
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (85.57–87.22)
                      Random forest                                                                                                                                                                            Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                   9    7.    6     8                                                                                                                                                                                                                             14. 9 2                                                                                                                                                                                                                                       99.91                                                                                                                                                                                                                                              90.97
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (90.27–91.59)
                      Random forest                                                                                                                                                                            Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                     84.57                                                                                                                                                                                                                          70.51                                                                                                                                                                                                                                   84.94                                                                                                                                                                                                                                         86.99
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (86.22–87.79)
                      Random forest                                                                                                                                                                       Over                                                                                                                                        Transductive                                                                             In-ward                                                                                                                                                        9    7.    7    0                                                                                                                                                                                                                              14 .4 3                                                                                                                                                                                                                                    99.95                                                                                                                                                                                                                                            8 9.78
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (89.32–90.44)
                      CatBoost                                                                                                                                                                                                                                                                            Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                   9    7.    6     8                                                                                                                                                                                                                              1 6.7 9                                                                                                                                                                                                                                     99.86                                                                                                                                                                                                                                          90.55
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (89.94–91.27)
                      CatBoost                                                                                                                                                                                                                                                                            Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                      74  .  8  9                                                                                                                                                                                                                       84.52                                                                                                                                                                                                                                   74  . 6   3                                                                                                                                                                                                                                             88.64
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (88.04–89.46)
                      CatBoost                                                                                                                                                                                                                                                                       Over                                                                                                                                        Transductive                                                                             In-ward                                                                                                                                                       9    7.    8     3                                                                                                                                                                                                                         23.39                                                                                                                                                                                                                                99.84                                                                                                                                                                                                                                         90.94
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       (90.24–91.69)
                      GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                  No                                                                                                                                                                                               82.47                                                                                                                                                                                                                        79.94                                                                                                                                                                                                                                 82.53                                                                                                                                                                                                                                          88.66
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (87.98–89.43)
                      GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                            Inductive                                                                                                            In-ward                                                                                                                                                      82.74                                                                                                                                                                                                                      83.00                                                                                                                                                                                                                                 82.73                                                                                                                                                                                                                                               91.23
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (90.61–91.85)
                      GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                             Transductive                                                                             In-ward                                                                                                                                                      96.18                                                                                                                                                                                                                        80.57                                                                                                                                                                                                                                96.60                                                                                                                                                                                                                                             96.13
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (95.63–96.60)
As for GNN simulations, the hyper-parameters of the baseline                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Results
models were optimized using Optuna [46], with 100 trials for
each model, sampling hyper-parameters with the TPESampler                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Performance of baseline and GNN models
[47] algorithm. The best set of hyper-parameters identified for                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Table 2 shows results obtained with the different colonization
each baseline model was made available at https://github.com/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  risk prediction models. For each model, we report the data bal-
ds4dh/hai_project/tree/master/models/controls. We also pro-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ance scenario (no balance, over-sampling, and under-sampling)
vide simulations that include edge information as node2vec                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     that led to the best performance. Except for k-NN, over- or
[34] feature vectors, concatenated to the original input features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              under-sampling did not improve performance for any   mo del.
of the baseline models. For any GNN or baseline model, con-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    In addition to the individual classic and graph-based models,
fidence inter vals were computed for AUROC using bootstrap-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    we created an ensemble model, which combines the results of
ping (number of bootstraps = 100, alpha level                         = 0.05). Shapley                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         classic machine learning models and GNN. We tried different
values were used to measure the importance of each feature to                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  model combinations and the one that led to the best perfor    -
the model’s predictions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       mance was an ensemble of CatB oost, random forest, and GNN
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   5

Fig.  3.  (A) Colonization models. We constructed 3 different graphs, in which links were created between patients only if they were in the same ward (left), only if they were
visited by the same healthcare worker (center), or both (right). (B) Graph-based machine learning pipeline for colonization risk prediction.
trained in an inductive setting, using ward links. We did not                                                                  For the metrics with a decision threshold, we report that,
use GNN trained in a transductive setting, since it is not                                                               for each model, the performance obtained with a threshold of
evaluated in the same way as other models. The predicted                                                                 0.5. k-NN achieves the highest accuracy (97.68%) and speci-
class probabilities of each selected model were averaged to                                                              ficity (99.91%). The GNN model trained in an inductive setting
generate a prediction. We tried different voting strategies                                                              with in-ward links obtains the best sensitivity (83.00%), at the
(unanimity, majority), which were inferior to the averaging                                                              cost of lower accuracy (82.74%) and specificity (82.73%). In
strateg y.                                                                                                               comparison, baseline models either achieve inferior perform-
     Graph-based models tend to outperform the baseline mod-                                                             ance (logistic regression and k-NN), or a more unbalanced
els. Particularly, the GNN trained in a transductive setting                                                             trade-off between sensitivity and specificity (random forest and
achieves the best performance overall (96.13% AUROC with                                                                 CatB oost). Finally, GNN trained in a transductive setting with
in-ward links). Importantly, the GNN trained in an inductive                                                             in-ward links yields not only high specificity (80.57%), but also
setting using in-ward links also outperforms baseline models                                                             high accuracy (96.18%) and sensitivity (96.60%). Overall,
(91.23% AUROC). Comparing different types of links for the                                                               GNN models achieve a more balanced predictive performance
GNN models, in-ward links produce the best performance,                                                                  between colonized and non-colonized patients, which, together
both in a transductive and in an inductive setting. These results                                                        with a high enough accuracy, may foster better practical appli-
suggest that network features enhance the predictive power of                                                            cations (at the expense of a reduced assessment set).
machine learning models for colonization risk prediction, and
that transmission patterns within the same ward are more                                                                 Stratified performance analysis for the GNN model
useful features. Note that, for all GNN conditions reported in                                                           Figure 4 shows AUROC for the best individual model—GNN
Table 2, the type of GNN layer that was selected by the hyper-                                                           trained in a transductive setting and using in-ward links only—
optimization process was always GraphSage. Results using dif-                                                            where the test dataset was stratified by species, specimen type,
ferent layer types are shown in Table S1. Finally, the ensemble                                                          length of stay and resistance profile. The results show that the
model—combining CatB oost, random forest, and GNN trained                                                                model provides consistent performance across different bac-
in an inductive setting and using in-ward links—improves per                           -                                 teria species, with 96.56% overall AUROC for species that
formance upon individual models (92.17% AUROC).                                                                          have at least 10 examples in the training dataset. The best
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  6

                Table  2. Performance of the different colonization prediction models. Ensemble model includes predictions from inductive-GNN, random
                forest, and CatBoost
                Model                                                                                                                                                                                                                                                      Data balance                                                                                                               Setting                                                                                                                                                  Links                                                                                                 Accuracy (%)                                                              Sensitivity (%)                                                              Specificity (%)                                                                                                   AUROC (%) (95% CI)
                Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                 82.37                                                                                                                                                                                                                            74  . 74                                                                                                                                                                                                                                  82.58                                                                                                                                                                                                                                              87.92
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (87.17–88.70)
                k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                                                                                                                                      -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                  80.15                                                                                                                                                                                                                         82.10                                                                                                                                                                                                                                   80.10                                                                                                                                                                                                                                              90.14
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (89.35–90.83)
                Random forest                                                                                                                                                                            Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                   9    7.    6     8                                                                                                                                                                                                                             14. 9 2                                                                                                                                                                                                                                       99.91                                                                                                                                                                                                                                              90.97
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    (90.27–91.59)
                CatBoost                                                                                                                                                                                                                                                                            Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                   9    7.    6     8                                                                                                                                                                                                                              1 6.7 9                                                                                                                                                                                                                                     99.86                                                                                                                                                                                                                                          90.55
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    (89.94–91.27)
                GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                            Inductive                                                                                                                                                         All                                                                                                                                                                                               84.23                                                                                                                                                                                                                         78.21                                                                                                                                                                                                                                   84.39                                                                                                                                                                                                                                            8 9.67
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (88.87–90.35)
                GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                            Inductive                                                                                                            In-ward                                                                                                                                                      82.74                                                                                                                                                                                                                      83.00                                                                                                                                                                                                                                 82.73                                                                                                                                                                                                                                               91.23
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (90.61–91.85)
                GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                   84.89                                                                                                                                                                                                                         71.55                                                                                                                                                                                                                                     85.25                                                                                                                                                                                                                                             87.90
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (87.14–88.67)
                GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                             Transductive                                                                                                                         All                                                                                                                                                                                               92.36                                                                                                                                                                                                                   80.50                                                                                                                                                                                                                               92.68                                                                                                                                                                                                                                           94.07
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (93.59–94.60)
                GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                             Transductive                                                                             In-ward                                                                                                                                                      96.18                                                                                                                                                                                                                        80.57                                                                                                                                                                                                                                96.60                                                                                                                                                                                                                                             96.13
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (95.63–96.60)
                GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                             Transductive                                                              Out-ward                                                                                                                                    83.55                                                                                                                                                                                                                          79.81                                                                                                                                                                                                                                     83.65                                                                                                                                                                                                                                           89.36
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (88.62–89.98)
                Ensemble                                                                                                                                                                                                                                                                    Non                                                                                                                                                                            Inductive                                                                                                            In-ward                                                                                                                                                        9    7.   4     3                                                                                                                                                                                                                               31.16                                                                                                                                                                                                                                      99.22                                                                                                                                                                                                                                               92.17
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (91.68–92.72)
performance is obser ved for E. cloacae                             (97.64%) (183 examples                                                                                                                                                                                                                                                                                                                                                         model and the GNN model trained in an inductive setting
in the testing set) while the worse is for Citrobacter freundii                                                                                                                                                                                                                                                                                                                                                                                    come second (gray and red curves). The ensemble model
(94.33%) (41 examples in the testing set). Similarly, consistent                                                                                                                                                                                                                                                                                                                                                                                   slightly outperforms the inductive GNN, especially for AMS
performance is obser ved across specimens, with AUROC var -                                                                                                                                                                                                                                                                                                                                                                                        Enterobacteriaceae.
ying from 95.52% for urine culture to 97.87% for bronchoal-
veolar lavage. The results of Fig. 4C show a decreasing trend                                                                                                                                                                                                                                                                                                                                                                                      Baseline models with node2vec embeddings
in performance as patients stay longer in the hospital, with                                                                                                                                                                                                                                                                                                                                                                                       As the baseline models in Table 2 do not have access to edge
AUROC as high as 96.88% for patients that stay 4 days or less                                                                                                                                                                                                                                                                                                                                                                                      information, we also controlled that using GNN layers is the
and as low as 91.02% for patients that stay more than 100 days.                                                                                                                                                                                                                                                                                                                                                                                    best way to exploit the topological features of the patient net-
Lastly, the model achieves similar predictive performance for                                                                                                                                                                                                                                                                                                                                                                                      work. For this reason, we included baseline model simulations
different resistance profiles with the lowest AUROC at 95.73%                                                                                                                                                                                                                                                                                                                                                                                      in which edge information is concatenated to the original input
for AMR Enterobacteriaceae and the highest score at 97.62%                                                                                                                                                                                                                                                                                                                                                                                         features. We used the node2vec [34] algorithm to embed net-
for MDR Enterobacteriaceae.                                                                                                                                                                                                                                                                                                                                                                                                                        work information into feature vectors. The node2vec algorithm
Predictive performance for AMS, AMR, and MDR                                                                                                                                                                                                                                                                                                                                                                                                       randomly walks on the network to generate sequences that rep-
                                                                                                                                                                                                                                                                                                                                                                                                                                                   resent the neighborhood of each node. A skip-gram [52] model
resistance profiles                                                                                                                                                                                                                                                                                                                                                                                                                                is trained with these node sequences and learns to produce fea-
The predictive performance for AMS, AMR, and MDR resist-                                                                                                                                                                                                                                                                                                                                                                                           ture vectors that preser ve both the local and global structure of
ance profiles and for the 3 most frequent MDR E nt e ro b a c t e r i a c e a e                                                                                                                                                                                                                                                                                                                                                                    the network. The parameters of node2vec were the following:
species is shown in Fig. 5. Like the general case (see Table 2),                                                                                                                                                                                                                                                                                                                                                                                   number of features =                                                  128, skip-gram window size =                                                                                                                                     5, maximum
the GNN model trained in a transductive setting is the best                                                                                                                                                                                                                                                                                                                                                                                        random walk length =                         32, number of random walks per root
model overall (blue cur ves) and the logistic regression model                                                                                                                                                                                                                                                                                                                                                                                     node = 10, p =                                                                                                                0.5, and q =                                                                   2.0. Table 3 shows the performance
is the worst model overall (orange curves). The ensemble                                                                                                                                                                                                                                                                                                                                                                                           of baseline models trained with this updated set of features. We
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     7

Fig. 4. Performance results per (A) species, (B) specimen type, (C) length of stay (expressed in days), and (D) resistance profile. Bal, bronchoalveolar lavage; AMS, antimicrobial
susceptible; AMR, antimicrobial resistant; MDR, multidrug resistant.
  Fig.       5.    Model performance for (A) antimicrobial susceptible (AMS), (B) antimicrobial resistant (AMR), and (C) multidrug-resistant (MDR) Enterobacteriaceae, and for
  representative MDR bacteria: (D) E. coli, (E) K. pneumoniae, and (F) E. cloacae.
report, for each model, the data balance scenario (no balance,                                                                                                                                 models both outperform any combination of baseline model
over-sampling, and under-     sampling) and link condition (in-                                                                                                                                and added edge features, in terms of AUROC. In terms of accu-
ward, out-ward, and all) that led to the best performance.                                                                                                                                     racy, sensitivity, and specificity, some combinations improve the
        Some baseline models achieve slightly higher AURO C when                                                                                                                               performance of baseline models. However, as for Table 2, these
edge information is added to the original features (logistic                                                                                                                                   combinations either achieve inferior perform ance, or a more
regression and CatB oost). Still, transductive and inductive GNN                                                                                                                               unbalanced trade-off between sensitivity and specificity. The
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  8

                     Table 3. Performance of the baseline models that use edge features as node2vec embeddings, concatenated to the original set of features,
                     as compared to the best GNN models
                     Model                                                                                                                                                                                                                                                      Data balance                                                                                                               Setting                                                                                                                                                  Links                                                                                                 Accuracy (%)                                                              Sensitivity (%)                                                              Specificity (%)                                                                                                   AUROC (%) (95% CI)
                     Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                 82.37                                                                                                                                                                                                                            74  . 74                                                                                                                                                                                                                                  82.58                                                                                                                                                                                                                                              87.92
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  (87.17–88.70)
                     Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                       89.19                                                                                                                                                                                                                         63.43                                                                                                                                                                                                                                 89.89                                                                                                                                                                                                                                                88.11
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (87.41–88.96)
                     Logistic regr.                                                                                                                                                                                                              Non                                                                                                                                             Transductive                                                                             In-ward                                                                                                                                                     80.77                                                                                                                                                                                                                         78.42                                                                                                                                                                                                                                80.84                                                                                                                                                                                                                                         88.59
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                (87.93–89.32)
                     k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                                                                                                                                      -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                  80.15                                                                                                                                                                                                                         82.10                                                                                                                                                                                                                                   80.10                                                                                                                                                                                                                                              90.14
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              (89.35–90.83)
                     k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                                                          Inductive                                                                                                            In-ward                                                                                                                                                   86.23                                                                                                                                                                                                                         6    7.     5     9                                                                                                                                                                                                                                      8 6.73                                                                                                                                                                                                                                                 87.66
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              (86.93–88.52)
                     k-NN                                                                                                                                                                                                                                                                                                                                       Under                                                                                                                           Transductive                                                                             In-ward                                                                                                                                                     72.46                                                                                                                                                                                                                             81.61                                                                                                                                                                                                                                        72.22                                                                                                                                                                                                                                             86.43
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                (85.57–87.22)
                     Random forest                                                                                                                                                                            Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                   9    7.    6     8                                                                                                                                                                                                                             14. 9 2                                                                                                                                                                                                                                       99.91                                                                                                                                                                                                                                              90.97
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (90.27–91.59)
                     Random forest                                                                                                                                                                            Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                     84.57                                                                                                                                                                                                                          70.51                                                                                                                                                                                                                                   84.94                                                                                                                                                                                                                                         86.99
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                (86.22–87.79)
                     Random forest                                                                                                                                                                       Over                                                                                                                                        Transductive                                                                             In-ward                                                                                                                                                        9    7.    7    0                                                                                                                                                                                                                              14 .4 3                                                                                                                                                                                                                                    99.95                                                                                                                                                                                                                                            8 9.78
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              (89.32–90.44)
                     CatBoost                                                                                                                                                                                                                                                                            Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                                    -                                                                                                                                                                                                                   9    7.    6     8                                                                                                                                                                                                                              1 6.7 9                                                                                                                                                                                                                                     99.86                                                                                                                                                                                                                                          90.55
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (89.94–91.27)
                     CatBoost                                                                                                                                                                                                                                                                            Non                                                                                                                                                                            Inductive                                                                                             Out-ward                                                                                                                                      74  .  8  9                                                                                                                                                                                                                       84.52                                                                                                                                                                                                                                   74  . 6   3                                                                                                                                                                                                                                             88.64
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             (88.04–89.46)
                     CatBoost                                                                                                                                                                                                                                                                       Over                                                                                                                                        Transductive                                                                             In-ward                                                                                                                                                       9    7.    8     3                                                                                                                                                                                                                         23.39                                                                                                                                                                                                                                99.84                                                                                                                                                                                                                                         90.94
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (90.24–91.69)
                     GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                                                                                                        -                                                                                                                                                                                                                                  No                                                                                                                                                                                               82.47                                                                                                                                                                                                                        79.94                                                                                                                                                                                                                                 82.53                                                                                                                                                                                                                                          88.66
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (87.98–89.43)
                     GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                                                            Inductive                                                                                                            In-ward                                                                                                                                                      82.74                                                                                                                                                                                                                      83.00                                                                                                                                                                                                                                 82.73                                                                                                                                                                                                                                               91.23
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                (90.61–91.85)
                     GNN                                                                                                                                                                                                                                                                                                                                                               Non                                                                                                                                             Transductive                                                                             In-ward                                                                                                                                                      96.18                                                                                                                                                                                                                        80.57                                                                                                                                                                                                                                96.60                                                                                                                                                                                                                                             96.13
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             (95.63–96.60)
best baseline combination is arguably CatBoost with inductive                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          values using the SHAP method [53]. For simplicity, we used
out-ward links, which marginally outperforms inductive GNN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             the results of the random forest model, as the baseline model
in terms of sensitivity (84.52%) but whose specificity drops sig-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      with the highest AUROC. Figure 6A shows the importance of
nificantly (74.63%). Additionally, AURO C for this combination                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         the top 11 features sorted by their predictive impact. Figure 6B
(88.64%) is notably lower than that of GNN models. Finally, we                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         shows the mean absolute value of every feature presented in
include a simulation in which GNN have no edges. GNN show                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Fig. 6A, computed over all data samples. As expected, length
a more significant AURO C performance boost from added edges                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           of stay in the ward and in the hospital has high impact on model
compared to baseline models, indicating they handle network                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            predictions. Indeed, the longer the stay in a ward or hospital,
information better than merely adding node2vec [34] features.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          the more likely it is for a patient to be classified by the model
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       as colonized. The number of patients in a ward also has a
Feature impact on model predictions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    large impact on model predictions. The higher the number of
To explain the importance and impact of the features used in                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           patients in the ward, the more probable the model output to be
our colonization risk prediction models, we calculated Shapley                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         positive (colonized). Despite its lower impact, female gender
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  9

influenced the model output in the positive (colonized) direc-                                                 the ward environment or utility. In Fig. 7, top right, patient
tion compared to male, which has the opposite effect. This                                                     154,208 (focus patient hereafter) stayed for 24 days in the
could be explained by the fact that the most prevalent bacteria                                                hospital and had an immediate link to patient 23,117 (non-
in the dataset were E. coli and that urinar y tract infections are                                             colonized) from a different ward via a healthcare worker, and
more common among women than men [54]. Similarly, the                                                          a second-degree connection to patient 111,558 (colonized)
neonatal intensive care unit (NICU) was less important to the                                                  from another ward. The latter patient and the focus patient were
model decisions than the medical intensive care unit (MICU)                                                    both colonized by K. pneumoniae                                 , like in the previous scenario.
and surgical intensive care unit (SICU). A patient in SICU and                                                 Hence, path 111,558–23,117–154,208 could be one of the pos-
MICU will more likely drive the model toward a positive output                                                 sible transmission routes within the hospital. For the third
(colonized), while a patient in NICU will more likely drive the                                                scenario, Fig. 7, bottom, patient 211,904 (focus patient hereaf-
model toward a negative output (non-colonized). These find-                                                    ter), male, stayed for 10 days and had a direct connection to
ings are aligned with previous risk factor analysis studies for                                                patient 36,255 via the same ward, both colonized, but by differ-
nosocomial infections in adult intensive care units [55]. Lastly,                                              ent bacteria. Moreover, these patients had a second-degree
it is noteworthy that many of the key features identified by the                                               connection to patient 158,476, female, via a healthcare worker
Shapley analysis pertain to ward-related information. This                                                     link, who was colonized by E. coli, as the focus patient. Since
aligns with the observation that in-ward links yield the best                                                  patient 158,476 was hospitalized for 7 days, she may have been
performance in GNNs.                                                                                           colonized by the same strain of the focus patient (or vice versa),
                                                                                                               who may have been previously colonized. Thus, the undirected
Colonization path analysis                                                                                     path 211,904–36,255–158,476 could be a possible transmission
A major advantage of using graph models and GNNs to predict                                                    route. Nevertheless, exact identification of transmission routes
colonization risks is that they naturally provide possible trans-                                              for such scenarios would require detailed phylogenetic anal-
mission paths via graph edges. In Fig. 7, we show 3 examples                                                   ysis of bacterial samples [56], not available in the MIMIC-III
of patients that were classified correctly as colonized by the                                                 dat ab as e.
transductive GNN model: nodes 57,627 (top left), 154,208 (top
right), and 211,904 (bottom). Nodes in green represent non-                                                    Discussion
colonized patients and nodes in red represent positive cul-
ture for Enterobacteriaceae. Filled colors represent colonized                                                 This study describes a machine learning model based on GNNs
patients. In the scenario of Fig. 7, top left, patient 57,627 (focus                                           to predict patients at risk of colonization by AMR and MDR
patient hereafter), who was colonized by K. pneumoniae       , st aye d                                        Enterobacteriaceae. We model the data as a graph to represent
in the hospital for 9 days and was directly linked to 4 patients:                                              possible connections and interactions between patients and
2 in the same room (1 non-colonized and 1 colonized) and 2                                                     healthcare workers inside the healthcare facility. Different graph
in different rooms (both non-colonized). Similar to the focus                                                  topologies were proposed based on geographic location and inter-
patient, patient 119,123 was colonized by K. pneumoniae                            and                         action with healthcare workers. We considered spatiotemporal
had the longest hospital stay in this subnetwork (11 days). Thus,                                              features, such as length of stay and ward movement, in addition
if both bacterial strains were genetically identical, a possible                                               to clinical and laboratory information, to encode patients via
transmission route could have been from patient 119,123 to                                                     node features in different graph topologies. Performance analyses
the focus patient or vice versa, or from a common source within                                                showed that GNN models provide robust predictive performance,
Fig. 6. Feature contribution to colonization risk prediction. (A) Shapley values for the top 11 features, sorted by their impact on model predictions. (B) Mean absolute value of
every feature presented in (A).
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             10

Fig. 7. Bacteria transmission scenarios via graph paths. Green nodes: non-colonized patients; red nodes: colonized patients.
often above AUROC of 90%, outperforming the classic machine                                                        patients potentially at risk, which will ultimately go through a
learning baselines used in our experiments. These results demon-                                                   screening process to duly confirm colonization. This process
strate the importance of incorporating topological features to                                                     is reactive and can be uncomfortable for patients, as well as
l e ar n  p atte r ns  of  p at i e nt  profiles that are more likely to be colo-                                  very costly and time consuming, thus preventing corrective
nized by MDR Enterobacteriaceae.                                                                                   actions from being taken in due time [59]. The predictive
     Other recent studies investigated the use of machine learn-                                                   model proposed in this study could help improve IPC measures
ing to predict colonization risk of AMR species from Entero-                                                       against Enterobacteriaceae, and other pathogens, in several
bacteriaceae [28,29], Enterococcaceae [27], and St aphy lo co ccace ae                                             ways. First, it could help to estimate the contact group with
[19] families, achieving robust predictive performance with an                                                     high accuracy, which, in turn, could lead to more effective
AUROC between 88% and 89%. Our study is the first to consider                                                      measures to curb transmission and infection. Second, possible
the colonization risk for AMR and MDR Enterobacteriaceae                                                           transmission paths could be automatically derived from the
family, responsible for the highest incidence of nosocomial                                                        graph model, providing hypotheses for transmission routes.
infections and HAI-related mortality [57], using a transmission                                                    Lastly, and more importantly, if deployed in a surveillance
network approach and spatiotemporal information. Moreover,                                                         mode, it could support early identification of potential patients
in contrast to previous studies, which were based on ensemble                                                      at risk of AMR and MDR colonization and enable outbreak
of tree methods such as random forest, our proposed meth-                                                          forewarning, which can deliver an even higher positive impact
odolog y used a deep learning approach and showed superior                                                         on life-saving and financial costs.
predictive power for the colonization prediction problem of                                                             Explainable artificial intelligence methods, such as the
Enterobacteriaceae. Another advantage of graph-based mod-                                                          Shapley values used to analyze our results, can provide an effec-
eling, as opposed to tabular data used in previous studies, is                                                     tive approach to interpret the model decisions and support the
that possible transmission routes can be inherently extracted                                                      identification of risk factors associated with colonization risks.
from the model, opening an avenue for data-driven transmis-                                                        Among the features having the highest impact on model pre-
sion route hypothesis generation.                                                                                  dictions, features such as length of stay, previous ward, and
     Following IPC guidelines, when an AMR Enterobacteriaceae                                                      gender have also been identified as relevant by previous epide-
outbreak occurs in a hospital or in a long-term care facility,                                                     miological studies that investigated risk factors for HAI colo-
colonized patients are initially isolated. Then, the contact                                                       nization and infection. For example, Patel et                                        al. [60] showed
group, i.e., patients potentially colonized by the outbreak strain,                                                that carbapenem-resistant K. pneumoniae                       infection was inde-
is identified to determine the magnitude of the outbreak and,                                                      pendently associated with longer length of stay before infection.
if required, additional IPC measures are applied [58]. Using                                                       McHaney-Lindstrom et                                   al. [61] showed that unit transfer
administrative information from the EHR system, contact trac-                                                      increases the odds of contracting an infection by 7%. For the
ing information can be obtained and used to determine other                                                        case of gender, the model not only identified this feature as a
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      11

risk factor but also showed that being female is associated with                                           models could be used to enhance IPC programs and reduce HAI
higher risk of Enterobacteriaceae colonization. This result was                                            burden. Given the data-driven approach of our method, we
found in previous risk analysis studies, which identified higher                                           expect that it could be expanded to other pathogens with similar
incidence rates of E. coli in women as compared to men [62].                                               transmission dynamics and to other healthcare settings.
    Applying machine learning algorithms to solve the task of
colonization risk prediction is challenging due to the imbal-                                              Ethical Approval
anced nature of the data. Machine learning models are often                                                This study used the MIMIC-III database, which is publicly avail-
biased toward the majority class (i.e., non-colonized in our                                               able and deidentified, thus exempt from institutional review
case), and in the worst-case scenario, they will ignore the                                                board approval. Researchers involved in this study completed
minority group entirely. Consequently, relying solely on accu-                                             the required training to access and work with the MIMIC-III
racy can be misleading when evaluating model performance.                                                  dat a.
A model that completely fails to predict the minority class (in
this case, the colonized group) could still obtain high accuracy.
Yet, given the consequences of false positives and negatives in                                            Acknowledgments
a real-case scenario, such a model would not be useful. False                                              Funding: This research was funded by the Joint Swiss–Portuguese
positives may lead to unnecessary isolation of patients and                                                Academic Program from the University of Applied Sciences and
exposure to unwanted risks and side effects, whereas false neg-                                            Arts Western Switzerland (HES-SO) and the Fundação para a
atives could result in the spread of a pathogen, delayed treat-                                            Ciência e Tecnologia (FCT). S.G.P. also acknowledges FCT for
ments, and worsened patient outcomes. To provide a more                                                    her direct funding (CEECINST/00051/2018) and her research
comprehensive view of our results, we reported sensitivity and                                             unit (UIDB/05704/2020). Funders were not involved in the study
specificity, which help understand both the ability of a model                                             design, data pre-processing, data analysis, interpretation, or
to correctly identify positive (colonized) and negative (non-                                              report writing.
colonized) cases, and AUROC, which offers a more holistic                                                  Author contributions: R.G. and A.B. designed and imple-
view on model outcomes. GNNs outperform all baseline mod-                                                  mented the models, and ran the experiments and analyses. R.G.
els in terms of AUROC. Moreover, GNNs trained in an induc-                                                 and D.T. wrote the manuscript draft. D.T. and S.G.P. concep-
tive setting tend to yield more balanced outcomes compared                                                 tualized the experiments and acquired funding. R.G., D.P., and
to classic models by achieving a higher sensitivity at the cost                                            S.G.P. curated the data. R.G., A.B., D.P., and D.T. analyzed the
of a lower specificity. In contrast, GNN trained in a transductive                                         data. All authors reviewed and approved the manuscript.
setting enhances sensitivity compared to baseline models while                                             Competing interests: The authors declare that they have no
maintaining high accuracy and specificity, at the cost of a more                                           competing interests.
complicated training process.
    Our study has several limitations, in terms of both data and
modeling. First, the model might not be able to generalize to                                              Data Availability
other hospitals as it was only evaluated in a single hospital unit                                         The MIMIC-III database is freely and publicly available through
dataset. Indeed, it is known that the epidemiolog y of HAI varies                                          PhysioNet. The code used to produce the results presented in
within different units and geographies [63]. Investigations of                                             this study is available at https://github.com/ds4dh/hai_project.
generalization performance for this type of models will warrant
specific future research. Second, while we avoided using pre-
dictors that might overlap with the dependent variable, such as                                            Supplementary Materials
antimicrobial consumption (e.g., trimethoprim-                                                 s u l f a m e t  h ox a z o l e  Table S1
antimicrobial medication could be a predictor for        E. coli[64]),
other predictors, such as diagnosis at admission, could still                                              References
have caused prediction bias. Nevertheless, given the distribu         -
tion of diagnoses in the dataset, we expect that this bias is
limited, if any. Third, our graph topology does not include                                                            1.                                                   Allegranzi B, Nejad SB, Combescure C, Graafmans W, Attar H,
environmental transmission, while it is known that indirect                                                        Donaldson L, Pittet D. Burden of endemic health-care-
transmission via the environment is an important part of HAI                                                       associated infection in developing countries: Systematic review
routes [65]. Due to the lack of fine-grained contact and sam     -                                                 and meta-analysis. Lancet                                . 2011;377(9761):228–241.
pling data in the MIMIC-III dataset, environment-related                                                               2.                                                   World Health Organization. Charter: Health worker safety: A
transmission pathways were ignored in our models as this                                                           priority for patient safety. Geneva (Switzerland): World Health
scenario could not be realistically captured. Understanding                                                        Organization; 2020.
the impact of environmental transmission on model perfor     -                                                         3.                                                   World Health Organization. Report on the burden of
mance could be another research direction. Lastly, due to the                                                      endemic health care-associated infection worldwide. Geneva
anonymization strateg y of MIMIC-III and, more specifically,                                                       (Switzerland): World Health Organization; 2011.
to the randomized time shifts, the data used in our experiments                                                          4.                                                     Klevens RM, Edwards JR, Richards CL Jr, Horan TC, Gaynes RP,
could be better regarded as synthetic data (generated from real                                                    Pollock DA, Cardo DM. Estimating health care-associated
data) rather than as real hospital data [66,67].                                                                   infections and deaths in US hospitals, 2002. Public Health Rep                                                                                                                .
    To conclude, we show that encoding topological informa-                                                        2007;122(2):160–166.
tion about patient interactions using GNNs can improve the                                                             5.                                                   Patient Carelink. Healthcare-acquired infections (HAIs).
predictive perform ance of AMR and MDR Enterobacteriaceae                                                          2022. Available at http://patientcarelink.org/improving-
colonization models and support the identification of patients                                                     patient-care/healthcare-acquired-infections-hais/ [accessed
potentially at risk of colonization or infection. Hence, these                                                     October 10, 2022].
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                12

            6.                                                   Tzouvelekis LS, Markogiannakis A, Piperaki E, Souli M,                                   semantic web technologies: Requirements, design, and
          Daikos GL. Treating infections caused by Carbapenemase-                                                                                         preliminar y evaluation. J Med Internet Res. 2012;14(3):
          producing Enterobacteriaceae. Clin Microbiol Infect                .                                                                            Article e2043.
          2014;20(9):862–872.                                                                                                                    23.                                                                      Hartvigsen T, Sen C, Brownell S, Teeple E, Kong X,
            7.                                                   Fritzenwanker M, Imirzalioglu C, Herold S, Wagenlehner FM,                               Rundensteiner EA. Early prediction of MRSA infections using
          Zimmer K-P, Chakraborty T. Treatment options for                                                                                                electronic health records. In: HEALTHINF. Setúbal (Portugal):
          Carbapenem-resistant gram-negative infections. Dtsch Arztebl                                                                                    SciTePress; 2018. p. 156–167.
          Int. 2018;115(20–21):345.                                                                                                              24.                                                                      Jeng S-L, Huang Z-J, Yang D-C, Teng C-H, Wang M-C.
            8.                                                   Marchetti A, Rossiter R. Economic burden of healthcare-                                  Machine learning to predict the development of recurrent
          associated infection in US acute care hospitals: Societal                                                                                       urinar y tract infection related to single uropathogen,
          perspective. J Med Econ. 2013;16(12):1399–1404.                                                                                                 Escherichia coli. Sci Rep. 2022;12(1):17216.
            9.                                                   Dalton KR, Rock C, Carroll KC, Davis MF. One health                             25.                                                                        Yang D, Xie Z, Xin X, Xue W, Zhang M. A model for predicting
          in hospitals: How understanding the dynamics of people,                                                                                         nosocomial Carbapenem-resistant Klebsiella pneumoniae
          animals, and the hospital built-environment can be used                                                                                         infection. Biomed Rep                                       . 2016;5(4):501–505.
          to better inform inter ventions for antimicrobial-resistant                                                                            26.                                                                      Sen C, Hartvigsen T, Rundensteiner E, Claypool K. Crest-risk
          gram-positive infections. Antimicrob Resist Infect Control                             .                                                        prediction for Clostridium difficile                     infection using multimodal
          2020;9(1):78.                                                                                                                                   data mining. In: Joint European Conference on Machine
10.                                                                      Denton M. Enterobacteriaceae. Int J Antimicrob Agents.                           Learning and Knowledge Discovery in Databases. Cham
          2007;29:S9–S22.                                                                                                                                 (Germany): Springer; 2017. p. 52–63.
11.                                                                      Jamrozik E, Selgelid MJ. Invisible epidemics: Ethics and                27.                                                                      van Niekerk JM, Lokate M, Braakman-Jansen LMA,
          asymptomatic infection. Monash Bioeth Rev. 2020;38(S1):1–16.                                                                                    van Gemert-Pijnen J, Stein A. Spatiotemporal prediction of
12.                                                                      Gao Y, Chen M, Cai M, Liu K, Wang Y, Zhou C, Chang Z,                            vancomycin-resistant Enterococcus                     colonisation. BMC Infect
          Zou Q, Xiao S, Cao Y, et al. An analysis of risk factors for                                                                                    Dis. 2022;22(1):1–12.
          Carbapenem-resistant Enterobacteriaceae infection. J Glob                                                                             28.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Ç  aǧlayan Ç, Barnes SL, Pineles LL, Harris AD, Klein EY.
          Antimicrob Resist. 2022;30:191–198.                                                                                                             A data-driven framework for identifying intensive care unit
13.                                                                      Akturk H, Sutcu M, Somer A, Aydın D, Cihan R, Ozdemir A,                         admissions colonized with multidrug-resistant organisms.
          Coban A, Ince Z, Citak A, Salman N. Carbapenem-resistant                                                                                        Front Public Health. 2022;10:Article 853757.
          Klebsiella pneumoniae colonization in pediatric and neonatal                                                                           29.                                                                      Goodman KE, Simner PJ, Klein EY, Kazmi AQ, Gadala A,
          intensive care units: Risk factors for progression to infection.                                                                                Toerper MF, Levin S, Tamma PD, Rock C, Cosgrove SE,
          Braz J Infect Dis. 2016;20(2):134–140.                                                                                                          et al. Predicting probability of perirectal colonization with
14.                                                                      World Health Organization. Health care without avoidable                         Carbapenem-resistant Enterobacteriaceae (CRE) and other
          infections: The critical role of infection prevention and control.                                                                              Carbapenem-resistant organisms (CROs) at hospital unit
          World Health Organization; 2016.                                                                                                                admission. Infect Control Hosp Epidemiol                                    . 2019;40(5):541–550.
15.                                                                      Liu Q, Yang J, Zhang J, Zhao F, Feng X, Wang X, Lyu J.                  30.                                                                      Kawaguchi K, Kaelbling LP, Bengio Y. Generalization
          Description of clinical characteristics of VAP patients in                                                                                      in deep learning. arXiv. 2017. https://doi.org/10.48550/
          MIMIC database. Front Pharmacol                . 2019;10:62.                                                                                    arXiv.1710.05468
16.                                                                      Lin J, Gu C, Zhang S, Tian L, Ren K, Cao Z, Han X. Sites                31.                                                                       Si Y, Du J, Li Z, Jiang X, Miller T, Wang F, Zheng WJ, Roberts K.
          and causes of infection in patients with sepsis-associated                                                                                      Deep representation learning of patient data from electronic
          liver dysfunction: A population study from the medical                                                                                          health records (EHR): A systematic review. J Biomed Inform          .
          information mart for intensive care III. Med Sci Monit.                                                                                         2021;115:Article 103671.
          2021;27:e928928–e928921.                                                                                                               32.                                                                      Kipf TN, Welling M. Semi-super vised classification with graph
17.                                                                       Zhao L, Gao Y, Guo S, Lu X, Yu S, Ge Z, Zhu H, Li Y. Prognosis                  convolutional networks. arXiv. 2016. https://doi.org/10.48550/
          of patients with sepsis and non-hepatic hyperammonemia: A                                                                                       arXiv.1609.02907
          cohort study. Med Sci Monit. 2020;26:e928573–e928571.                                                                                  33.                                                                      Johnson AE, Pollard TJ, Shen L, Lehman LH, Feng M,
18.                                                                      Peiffer-Smadja N, Rawson TM, Ahmad R, Buchard A,                                 Ghassemi M, Moody B, Szolovits P, Anthony Celi L, Mark RG.
          Georgiou P, Lescure F-X, Birgand G, Holmes AH. Machine                                                                                          MIMIC-III, a freely accessible critical care database. Sci data.
          learning for clinical decision support in infectious diseases: A                                                                                2016;3(1):1–9.
          narrative review of current applications. Clin Microbiol Infect                              .                                         34.                                                                      Grover A, Leskovec J. Node2vec: Scalable feature learning
          2020;26(5):584–595.                                                                                                                             for networks. In: Proceedings of the 22nd ACM SIGKDD
19.                                                                           Hirano Y, Shinmoto K, Okada Y, Suga K, Bombard J, Murahata S,               International Conference on Knowledge Discovery and Data
          Shrestha M, Ocheja P, Tanaka A. Machine learning approach to                                                                                    Mining. (New York, USA): Association for Computing
          predict positive screening of methicillin-resistant Staphylococcus                                                                              Machiner y ; 2016. p. 855–864.
          aureus during mechanical ventilation using synthetic dataset                                                                           35.                                                                      Magiorakos A-P, Srinivasan A, Carey RB, Carmeli Y,
          from MIMIC-IV database. Front  Me d         . 2021;8:694520.                                                                                    Falagas ME, Giske CG, Harbarth S, Hindler JF, Kahlmeter G,
 20.                                                                            Baldominos A, Puello A, Oğul H, Aşuroğlu T, Colomo-Palacios R.            Olsson-Liljequist B, et al. Multidrug-resistant, extensively
          Predicting infections using computational intelligence—A                                                                                        drug-resistant and Pandrug-resistant bacteria: An international
          systematic review. IEEE Access. 2020;8:31083–31102.                                                                                             expert proposal for interim standard definitions for acquired
21.                                                                      Teodoro D, Lovis C. Empirical mode decomposition and                             resistance. Clin Microbiol Infect. 2012;18(3):268–281.
          K-nearest embedding vectors for timely analyses of antibiotic                                                                          36.                                                                      Schoch CL, Ciufo S, Domrachev M, Hotton CL, Kannan S,
          resistance trends. PLoS One. 2013;8(4):Article e61180.                                                                                          Khovanskaya R, Leipe D, Mcveigh R, O’Neill K, Robbertse B,
22.                                                                      Teodoro D, Pasche E, Gobeill J, Emonet S, Ruch P, Lovis C.                       et al. NCBI taxonomy : A comprehensive update on curation,
          Building a transnational biosur veillance network using                                                                                         resources and tools. Database (Oxford). 2020;2020:baaa062.
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                13

37.                                                                        Bonten MJ, Gaillard CA, Johanson WG Jr, van Tiel FH,                            55.                                                                      Vincent J-L. Nosocomial infections in adult intensive-care
          Smeets HG, Van Der Geest S, Stobberingh EE. Colonization                                                                                                   units. Lancet                                            . 2003;361(9374):2068–2077.
          in patients receiving and not receiving topical antimicrobial                                                                                    56.                                                                      Abbas M, Robalo Nunes T, Martischang R, Zingg W, Iten A,
          prophylaxis. Am J Respir Crit Care Med. 1994;150(5):1332–1340.                                                                                             Pittet D, Harbarth S. Nosocomial transmission and outbreaks
38.                                                                      Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B,                                  of coronavirus disease 2019: The need to protect both patients
          Grisel O, Blondel M, Prettenhofer P, Weiss R, Dubourg V.                                                                                                   and healthcare workers. Antimicrob Resist Infect Control                             .
          Scikit-Learn: Machine learning in python. J Mach Learn Res.                                                                                                2021;10(1):1–13.
          2011;12:2825–2830.                                                                                                                               57.                                                                        Cassini A, Högberg LD, Plachouras D, Quattrocchi A, Hoxha A,
39.                                                                      Scarselli F, Gori M, Tsoi AC, Hagenbuchner M, Monfardini G.                                 Simonsen GS, Colomb-Cotinat M, Kretzschmar ME,
          The graph neural network model. IEEE Trans Neural Netw.                                                                                                    Devleesschauwer B, Cecchini M, et al. Attributable deaths
          2008;20(1):61–80.                                                                                                                                          and disability-adjusted life-years caused by infections with
40.                                                                      Battaglia PW, Hamrick JB, Bapst V, Sanchez-Gonzalez A,                                      antibiotic-resistant bacteria in the EU and the European
          Zambaldi V, Malinowski M, Tacchetti A, Raposo D, Santoro                                                                                                   economic area in 2015: A population-level modelling analysis.
          A, Faulkner R. Relational inductive biases, deep learning,                                                                                                 Lancet Infect Dis. 2019;19(1):56–66.
          and graph networks. arXiv. 2018. https://doi.org/10.48550/                                                                                       58.                                                                      Boonstra MB, Spijkerman DC, Voor AF, van der Laan RJ,
          arXiv.1806.01261                                                                                                                                           Bode LG, van Vianen W, Klaassen CH, Vos MC, Severin JA.
41.                                                                      Bronstein MM, Bruna J, Cohen T, Veličković P. Geometric                                     An outbreak of ST307 extended-spectrum beta-lactamase
          deep learning: Grids, groups, graphs, geodesics, and gauges.                                                                                               (ESBL)–producing Klebsiella pneumoniae                                       in a rehabilitation
          arXiv. 2021. https://doi.org/10.48550/arXiv.2104.13478                                                                                                     center: An unusual source and route of transmission. Infect
42.                                                                      Veličković P, Cucurull G, Casanova A, Romero A, Lio P,                                      Control Hosp Epidemiol. 2020;41(1):31–36.
          Bengio Y. Graph attention networks. arXiv. 2017. https://doi.                                                                                    59.                                                                      Dik J-WH, Hendrix R, Poelman R, Niesters HG, Postma MJ,
          org/10.48550/arXiv.1710.10903                                                                                                                              Sinha B, Friedrich AW. Measuring the impact of antimicrobial
43.                                                                      Hamilton W, Ying Z, Leskovec J. Inductive representation                                    stewardship programs. Expert Rev Anti-Infect Ther.
          learning on large graphs. Adv Neural Inf Process Syst. 2017.                                                                                               2016;14(6):569–575.
44.                                                                      Lin T-Y, Goyal P, Girshick R, He K, Dollár P. Focal loss                          60.                                                                          Patel G, Huprikar S, Factor SH, Jenkins SG, Calfee DP. Outcomes
          for dense object detection. In: Proceedings of the IEEE                                                                                                    of Carbapenem-resistant Klebsiella pneumoniae infection and the
          International Conference on Computer Vision. New York                                                                                                      impact of antimicrobial and adjunctive therapies. Infect Control
          (USA): Institute of Electrical and Electronics Engineers                                                                                                   Hosp Epidemiol. 2008;29(12):1099–1106.
          (IEEE); 2017. p. 2980–2988.                                                                                                                      61.                                                                      McHaney-Lindstrom M, Hebert C, Flaherty J, Mangino JE,
45.                                                                      Loshchilov I, Hutter F. Decoupled weight decay regularization.                              Moffatt-Bruce S, Root ED. Analysis of intra-hospital transfers
          arXiv. 2017. https://doi.org/10.48550/arXiv.1711.05101                                                                                                     and hospital-onset clostridium difficile infection. J Hosp Infect                                    .
46.                                                                      Akiba T, Sano S, Yanase T, Ohta T, Koyama M. Optuna: A                                      2019;102(2):168–169.
          next-generation hyperparameter optimization framework. In:                                                                                       62.                                                                      Uslan DZ, Crane SJ, Steckelberg JM, Cockerill FR, Sauver JLS,
          Proceedings of the 25th ACM SIGKDD International Conference                                                                                                Wilson WR, Baddour LM. Age-and sex-associated trends in
          on Knowledge Discovery & Data Mining.                                                     New York (USA):                                                  bloodstream infection: A population-based study in Olmsted
          Association for Computing Machiner y ; 2019. p. 2623–2631.                                                                                                 County, Minnesota. Arch  Int  Med                               . 2007;167(8):834–839.
47.                                                                      Bergstra J, Bardenet R, Bengio Y, Kégl B. Algorithms for hyper-                   63.                                                                      Livermore DM, Pearson A. Antibiotic resistance: Location,
          parameter optimization. Adv Neural Inf Process Syst. 2011.                                                                                                 location, location. Clin Microbiol Infect                                     . 2007;13:7–16.
48.                                                                      Cunningham P, Delany SJ. K-nearest neighbour classifiers-a                        64.                                                                      Brown PD, Freeman A, Foxman B. Prevalence and predictors
          tutorial. ACM Comput Surv (CSUR). 2021;54(6):1–25.                                                                                                         of trimethoprim-sulfamethoxazole resistance among
49.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Wr ig ht                                                    RE.        Logistic regression. Washington (DC): American uropathogenic Escherichia coli                                                                          isolates in Michigan. Clin Infect
          Psychological Association; 1995.                                                                                                                           Dis. 2002;34(8):1061–1066.
50.                                                                      Breiman L. Random forests. Mach  L ear n                                           . 2001;45(1):5–32.65.                                                                       Blanco N, O’Hara LM, Harris AD. Transmission pathways of
51.                                                                       Prokhorenkova L, Gusev G, Vorobev A, Dorogush AV, Gulin A.                                 multidrug-resistant organisms in the hospital setting: A scoping
          CatBoost: Unbiased boosting with categorical features. Adv                                                                                                 review. Infect Control Hosp Epidemiol. 2019;40(4):447–456.
          Neural Inf Process Syst. 2018;31.                                                                                                                66.                                                                      Hittmeir M, Ekelhart A, Mayer R. Utility and privacy
52.                                                                      Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J.                                         assessments of synthetic data for regression tasks. In: 2019
          Distributed representations of words and phrases and their                                                                                                 IEEE International Conference on Big Data (Big Data). New
          compositionality. Adv Neural Inf Process Syst. 2013.                                                                                                       York (USA): IEEE; 2019. p. 5763–5772
53.                                                                      Lundberg SM, Lee S-I. A unified approach to interpreting                          67.                                                                      Hittmeir M, Ekelhart A, Mayer R. On the utility of synthetic
          model predictions. Adv Neural Inf Process Syst. 2017.                                                                                                      data: An empirical evaluation on machine learning tasks. In:
54.                                                                      Harrington RD, Hooton TM. Urinar y tract infection risk                                     Proceedings of the 14th International Conference on Availability,
          factors and gender. J Gend Specif Med. 2000;3(8):27–34.                                                                                                    Reliability and Security. 2019. p. 1–6.
Gouareb et al. 2023 | https://doi.org/10.34133/hds.0099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                14

