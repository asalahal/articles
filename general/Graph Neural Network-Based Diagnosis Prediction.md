Big          Data
Volume          00,          Number          00,          2020
ª          Mary          Ann          Liebert,          Inc.
DOI:          10.1089/big.2020.0070
Graph                      Neural                      Network-Based                      Diagnosis                      Prediction
Yang             Li,1,*             Buyue             Qian,2             Xianli             Zhang,1             and             Hui             Liu2
                  Abstract
                  Diagnosis          prediction          is          an          important          predictive          task          in          health          care          that          aims          to          predict          the          patient          future          diagnosis
                  based                on                their                historical                medical                records.                 A                crucial                 requirement                 for                 this                task                 is                to                effectively                 model                 the                high-
                  dimensional,          noisy,          and          temporal         electronic          health         record          (EHR)          data.         Existing          studies         fulﬁll          this          requirement          by         ap-
                  plying               recurrent                neural               networks               with                attention                mechanisms,                but               facing                data                insufﬁciency                and                noise                problem.
                  Recently,          more          accurate         and          robust          medical         knowledge-guided          methods         have         been         proposed         and          have         achieved
                  superior             performance.             These             methods             inject            the             knowledge             from             a             graph             structure             medical             ontology             into            deep
                  models                   via                    attention                   mechanisms                   to                   provide                    supplementary                    information                   of                   the                    input                   data.                   However,                    these
                  methods             only              partially              leverage              the             knowledge              graph              and              neglect              the             global              structure              information,              which             is             an
                  important                feature.                 To                address                 this                 problem,                 we                 propose                 an                 end-to-end                robust                 solution,                 namely                 Graph                Neural
                  Network-Based        Diagnosis        Prediction        (GNDP).        First,        we        propose        to        utilize        the        medical        knowledge        graph        as        an        internal
                  information          of          a          patient          by          constructing          sequential          patient          graphs.          These          graphs          not          only          carry          the          historical          infor-
                  mation         from         the         EHR        but         also         infuse         with         domain         knowledge.        Then        we        design         a         robust         diagnosis         prediction         model
                  based          on           a           spatial-temporal          graph          convolutional          network.           The          proposed           model          extracts           meaningful           features           from
                  sequential         graph         EHR        data         effectively        through        multiple        spatial-temporal        graph        convolution        units         to        generate        robust
                  patients’          representations          for          accurate          diagnosis          predictions.          We          evaluate          the          performance          of          GNDP          against          a          set          of
                  state-of-the-art                  methods                  on                 two                  real-world                 medical                  data                  sets,                  the                 results                  demonstrate                  that                 our                 methods                 can
                  achieve            a            better            utilization            of            knowledge            graph            and            improve            the            accuracy            on            diagnosis            prediction            tasks.
                  Keywords:             deep             learning;             health             care             informatics;             medical             knowledge             graph
Introduction                                                                                                                                                                                                In                   recent                   years,                   the                   emerging                   deep                   learning                   tech-
The             accumulation             of             patients’            electronic             health            record                                                                       niques                            attract                            considerable                            attention                           to                            researches
(EHR)                 or                 electronic                 medical                 record                 data                 lays                 a                  solid              and              have              been              widely              applied              in              various              domains,              in-
foundation              for              applying              machine              learning              approaches                                                                               cluding                     computer                     vision,5                     natural                     language                     process-
in        medical        domain,        thus        enabling        the        possibility        of        clin-                                                                                  ing,6                                            and                                            clinical                                            predictions.7                                            Different                                            from
ical            predictive            tasks.1            Such            predictive            tasks            aim            to            pre-                                                  traditional                       machine                       learning                       models                        that                       require                        a
dict            an            individual’s           future            health           status            to           improve            the                                                      manual               feature               engineering               procedure               by               domain               ex-
quality                of                personalized                health                care.                Diagnosis                predic-                                                   perts,             deep              learning             models             learn             the             data             representa-
tion,                   which                    predicts                    patients’                   future                    diagnosis                   based                               tion                         or                         the                         task-related                         features                         automatically                         and
on         their         historical         EHR         data,         is         one         of         the         most         popular                                                           effectively           from           the           source           data.           With           proper           objective
yet             complex             tasks             in             the            research             community.             On            one                                                  function               and                sufﬁcient               quality                data,                deep                models                can
hand,              diagnosis              prediction              may              possibly              contribute              to                                                                possibly           achieve           superior           performance           than           traditional
clinical                anticipation                and                precision                diagnosis.2                On                the                                                   models                     in                     various                     tasks.                     Recurrent                     neural                     networks
other              hand,             the             high             dimensionality,              temporal             nature,                                                                    (RNNs),            which            are            a            catalog            of            remarkable            deep            mod-
and              noisy              of              EHR              data              bring              challenges              to              traditional                                      els,                    have                   been                    broadly                    applied                    to                   clinical                    prediction
machine             learning             methods.3,4                                                                                                                                               tasks.2,8–11                      The             literatures             indicate             that             RNNs             have             an
1National         Engineering         Lab         for         Big         Data         Analytics,         School         of         Electronic         and         Information         Engineering,         Xi’an         Jiaotong         University,         Xi’an,         China.
2School         of         Electronic         and         Information         Engineering,         Xi’an         Jiaotong         University,         Xi’an,         China.
An         earlier         version         of         this         study         was         presented         at         the         SIAM         International         Conference         on         Data         Mining         (SDM2020).
*Address          correspondence          to:          Yang          Li,          National          Engineering          Lab          for          Big          Data           Analytics,           School          of          Electronic          and          Information           Engineering,          Xi’an          Jiaotong           University,           Xi’an,
Shaanxi         710049,         China,        E-mail:        vigilee@stu.xjtu.edu.cn
                                                                                                                                                                                             1

2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    LI           ET           AL.
outstanding                 ability                 to                 model                 sequential                 relationships,                                                                                        This            article            proposes           a            knowledge-guided            predictive
thus                              achieving                              impressive                              success                              in                              EHR-related                    method,                          namely                         the                         Graph                         Neural                         Network-Based
tasks.                  However,                  it                  also                  has                  been                  discussed                  that                  deep                         Diagnosis            Prediction           (GNDP),           to           perform           accurate            di-
models              are              vulnerable              to              data              insufﬁciency              and              noise,                                                                     agnosis                           prediction                           by                           fully                           exploiting                           the                           medical
which                     are                     regularly                     existing                     in                     EHR.11,12                     Moreover,                                          knowledge.                                Different                                from                                existing                                methods                                that
RNNs                             cannot                             handle                             long                             sequences                             effectively.10                         adopt             RNNs             and             attention             mechanisms,             the             proposed
Therefore,               the               challenge                in                diagnosis               prediction               tasks                                                                         GNDP                   is                   developed                   based                   on                   the                   framework                   of                   the
cannot             be             tackled             by             utilizing             deep             models             solely.                                                                               spatial-temporal                           graph                          convolutional                           network                           (ST-
         To          address          the          aforementioned          problem,         researchers                                                                                                              GCN).14          Moreover,         we          propose         to          reconstruct          patients’
propose            knowledge-guided            clinical            predictive            methods                                                                                                                     EHR             in            the            spatial-temporal            graph            format,             which            nat-
that                   incorporate                   domain                   knowledge                   into                   deep                   mod-                                                         urally                 infuses                 medical                 knowledge                 into                 data                 and                 con-
els.9,11–13                           These                  methods                  make                  use                  of                  the                  strong                  se-                verts              it              to              internal              information.              Figures              1              and              2              show
quential                                modeling                                ability                               of                                RNNs                               to                               learn                                thetoy                    examples                    of                    the                    input                    structure                    for                    the                    existing
patients’               representations               from               EHR               data               while               inject-                                                                            method                  and                  the                  proposed                  method.                  With                  the                  uniﬁed
ing            supplementary            information            into            the            model            to            alle-                                                                                   framework              and              graph             format             input,             GNDP             can              lever-
viate               data               insufﬁciency               and               noise.               The               information               is                                                              age            the            sequential            information            from            EHR            and            domain
either         extracted         from         a         medical         ontology         or        the         medical                                                                                               knowledge              from             medical              ontologies              simultaneously              to
relations                  within                  EHR.                  Graph-based                  Attention                  Model                                                                               learn                  more                  robust                  and                  accurate                  patients’                  representa-
(GRAM)12              adopts              RNNs              to              model              EHR              data              and              uti-                                                              tions               and               perform               more               accurate               predictions               in               diag-
lizes             a             medical             ontology             as             a             knowledge             graph             to             pro-                                                    nosis             prediction             tasks.
vide                supplementary                information                in                the                training                stage                                                                                The             contributions             of             this             article             are             as             follows:
via                       a                       graph-attention                       mechanism.                       Knowledge-based                                                                                      We               propose               GNDP,               a               graph               convolution               network-
Attention         Model         (KAME)11         further         exploits         the         knowl-                                                                                                                 based,                         end-to-end,                         and                         robust                         diagnosis                         prediction
edge          in          the          predicting          stage          of          a          deep          model          and          brings                                                                    method                  that                  can                  make                  use                  of                  the                  underlying                  spatial
out         a         state-of-the-art         (SOTA)         performance         in         diagnosis                                                                                                               and                    temporal                   dependence                    of                   EHR                    data                    comprehen-
prediction                    tasks.                    Co-attention                   memory                    networks                   for                                                                      sively            to            improve            the            accuracy            of            diagnosis            prediction.
diagnosis                             prediction                             (CAMP)13                             applies                             augmented                                                               We            introduce            a            spatial-temporal             patient            graph            con-
RNN-based                     models                     with                     a                     knowledge                     graph                     to                     en-                           struction                   method.                   By                  integrating                   patients’                   EHR                  data
hance                  the                  prediction                  accuracy.                  These                  works                  indicate                                                            with           the           medical           knowledge           graph,           the           domain           knowl-
that                    the                    utilization                    of                    the                    medical                    knowledge                    graph                             edge           is           converted          into          internal          information          of           the          data,
will          improve          the          model’s          robustness          against          data          insuf-                                                                                               thus            beneﬁting            deep            models            to            extract            more            meaning-
ﬁciency               and               noise               effectively,               thus               beneﬁting               the               pre-                                                             ful             features.
diction                                   performance.                                   In                                   medical                                   ontologies                                   (i.e.,   We                              empirically                               demonstrate                               that                               the                              proposed
International         Classiﬁcation         of         Diseases            {         [ICD],         Clinical                                                                                                         GNDP                outperforms                SOTA                RNN                and                attention-based
Classiﬁcations                     Software          {                     [CCS]),                     the                     medical                     events                                                    methods             in             diagnosis             prediction             task.
(i.e.,                                 diagnosis,                                medications,                                and                                procedures)                                 are               This         article         is         organized         as         follows:         the         Related         Work
encoded             following             a             hierarchical             structure             and             in             par-                                                                           section           discusses           the           existing           studies           that           are           related           to
ent–child                       relationships,                       which                       is                       a                       graph                       naturally.                             this             work,             including             the             description             of             EHR             data.             The
Regardless               of               the               success,               the               above               studies               only               par-                                               details          of          the          proposed          GNDP          are          provided          in          the          Pro-
tially          make          use          of          the          information          derived          from          knowl-                                                                                       posed                 Method                 section,                 including                 the                 basic                 notations,
edge                       graphs                       (i.e.,                       medical                       codes                       co-occurrence                       and                               the               problem               deﬁnition,               and               the               network               architecture.
parent–child                relationships),                yet                unable                to                capture                the                                                                     In                 the                Experiments                and                 Evaluations                section,                ablation
graph         structure         features         that         may         be         equally         important.                                                                                                      and               comparative               experimental               results               are               provided              as
Furthermore,             these             studies             exploit             the             medical             knowl-                                                                                        well              as              the              implementation              detail.              At              last,              the              conclu-
edge          from          ontologies         as          external          information          separated                                                                                                          sions             are             presented             in             the             Conclusions             section.
from          EHR          data,          which         may          introduce         extra          noise          when
training             the             deep             model.                                                                                                                                                         Related           Work
                                                                                                                                                                                                                     This                section                provides                a                description                of                EHR                data                and
{http://www.icd9data.com/                                                                                                                                                                                            discusses                      the                      existing                      works                      in                      a                      clinical                      predictive
{https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp                                                                                                                                                              method,             especially             the             diagnosis             prediction             method.

GNDP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3
                FIG.            1.                                        The            input            structure            of            RNN-based            methods.            HER,            electronic            health            record;            RNN,            recurrent            neural
                network.
          EHR            systems            are            primarily             designed            for            the            admin-                                                                                                               tion.                  RETAIN                  utilizes                  RNNs                  to                  model                  reverse                  time-
istration             aspect.15             Such             systems             store             patients’             records                                                                                                                        ordered         sequential         EHR         data.         This         is         inspired         by         a         clin-
that                 consist                of                 massive                 and                 diverse                 medical                 variables                                                                                    ical              practice              that              the              up-to-date              health              status              of              a              pa-
and              information              in              a              sequential              order              associated              with                                                                                                        tient                    is                    more                    informative                    than                    the                    previous.                    Dipole
their                 visits                 to                 the                 hospital.1                 Nowadays,                 EHR                 systems                                                                                    applies           bi-directional           long           short-term           memory           to           han-
are               broadly               applied               worldwide               and               have               accumulated                                                                                                                  dle             long             sequences,             thus             enhancing             the             data             modeling
a                      tremendous                      amount                      of                      patients’                      historical                      data.15                                                                       ability                         of                         predictive                         models.                          These                         methods                         prove
Based           on           this,           researchers           apply           EHR           data           for           multiple                                                                                                                  that          RNNs          are          effective          to          model          patients’          historical          re-
clinical                  predictive                  tasks                  such                  as                 diagnosis                  prediction,                                                                                            cords.            However,            both            of           them            still            suffer            from            data           in-
risk         prediction,         medicine         recommendation,         and         disease                                                                                                                                                           sufﬁciency             and             noise.            12
progression.                                                                                                                                                                                                                                                       In                        practice,                       data                       insufﬁciency                       and                        noise                        are                        in-
          Diagnosis                prediction                is                one                 of                the                 most                important                                                                                  variably                 existing                 in                 EHR.1,11,12                  As                 it                 is                hard                 to                 solve
and                        difﬁcult                        tasks                        in                        clinical                        predictions                        based                        on                                    these                         problems                          through                         data                          preprocessing                         proce-
EHR          data.          This          task          aims          to          predict          the          patients’          future                                                                                                               dures,                  researchers                  propose                  to                  utilize                  domain                  knowl-
diagnoses                     based                     on                     their                    historical                     medical                     records,                                                                             edge                        to                        provide                        supplementary                        information                       of                        the
and           a           crucial           requirement           for           it           is           to           model           the           patient                                                                                            original               data               for               deep               models.               GRAM12               creates               a               co-
visits                 effectively.                 Reverse                 Time                 Attention                 Mechanism                                                                                                                    occurrence                   matrix                   that                   consists                   of                   medical                   codes                   in
(RETAIN)8               and               Dipole10                are                two               inspiring               studies                to                                                                                                EHR                       data                       and                       ancestor                       codes                       in                       a                       medical                       ontol-
adopt                  deep                 learning                  techniques                 for                 diagnosis                 predic-                                                                                                  ogy,                and                the                use                is                to                generate                reliable                medical                code
                FIG.         2.                                         The         input         structure         of         the         proposed         GNDP.         GNDP,         Graph         Neural         Network-Based         Diagnosis         Prediction.

4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    LI           ET           AL.
representations             via            an             attention             mechanism.             KAME11                                                                                                                                           Proposed           Method
makes         use         of         the         medical         ontology         to         generate         both         the                                                                                                                          This         section         is          divided         into         three         parts.         First,         it         deﬁnes         the
medical                 code                 and                 ancestor                  code                 representations                 and                                                                                                     basic                   notations                   and                   the                   diagnosis                   predication.                   Then,                   it
apply                     them                     to                     the                     training                     and                     predicting                     stage                     of                                      provides             a             detailed             description             of             the             method             to             convert
their                 model                via                attention                mechanisms.                 CAMP13                also                                                                                                           EHR                data                and                medical                ontology                into                a                graph                structure.
developed                a                knowledge-guided                method                based                on                the                                                                                                              At              last,              we              expatiate              the              framework              of              GNDP.
medical                  ontology                  and                   augmented                  memory                  networks
that              share              the             same             concept             with             KAME.             All              of              these                                                                                     Basic             notations
methods                 experimentally                 prove                 that                 the                 utilization                 of                                                                                                    The               entire               set               of               unique               medical               codes               (i.e.,               diagnose
domain           knowledge           can           effectively           improve           the           perfor-                                                                                                                                        code,                              procedure,                              and                              medication                              code)                              from                              the
mance               of               RNN-based               deep               models               on               diagnosis               pre-                                                                                                      EHR                                  data                                  set                                  can                                  be                                  denoted                                  by                                  M      =     fm1  ,       m2  ,
diction             tasks.                                                                                                                                                                                                                              m3  ,                      /C1/C1/C1                                                           ,       mjM j g              where                          Mjj              is              the              total              amount.              Patient
          However,              the              knowledge              information              from              medical                                                                                                                              p               who               has               T               visit               records               can               be               represented               as               a               se-
ontologies                 may                 not                 be                 leveraged                 comprehensively                 by                                                                                                      quence                     of                     visits:                P  p        =     fx p1   ,       xp2    ,                     /C1/C1/C1                                                           ,       x pT   g.                     Each                     visit                    x/C3t
the                      above                     methods.                      The                     ontologies                      are                      graphs                      that                                                      from                    an                    arbitrary                    patient                    contains                    multiple                    medical
model         a         set         of         medical         concepts         and         their         relationships.                                                                                                                                codes             from             code             set             M             (x/C3t                 /C18                                             M ).
The                above                studies                utilize                these                graphs                by                creating                an                                                                                      The                medical                ontology             G                used                in                previous                works                is
embedding                    matrix                    that                    consists                    of                    nodes                    from                    data                                                                  CCS,               which              consists              of              diverse              medical              concepts              with
and                        their                        parent                        nodes                        from                        an                        ontology                        initially,                                     parent–child                 relationships                 in                 a                 hierarchical                 structure.
and                        then                        generate                       code                        representations                       that                        infuse                                                              The         leaf         nodes         are         in        the         lowest        layer        of       G         and         represent
with                  knowledge                  via                  attention                  mechanisms.                  Although                                                                                                                  speciﬁc           medical           concepts           as           same           as           the           medical           codes
these                     studies                     leverage                     the                     parent–child                     relationships                                                                                               in          the          EHR          data          set.          The          ancestor         nodes,          the          more          gen-
in           the          knowledge          graph,           they          neglect           and           are          incapable                                                                                                                      eral          concepts,          are          in          the          higher          layers          and         related          to          the
of           extracting           the           global           structure           information,           which           is                                                                                                                          leaf           nodes.           With           medical           code           set           M,           we           can           get           a           sub-
a             crucial             feature             of             a             graph.                                                                                                                                                               ontology         GM         =       M       þ     L,            where         L      =     fa1  ,       a2  ,                      /C1/C1/C1                                                           ,       ajLj g            are
          Recently,                                graph                                neural                               networks                                (GNNs)                                have                                         jLj                ancestor                nodes                that                 related                 to                M                from             G.                In                this
attracted               wide               attention               from               the               deep               learning               com-                                                                                                  work,                    the                    subontology               GM                       is                    used                    as                    an                    undirected
munity.16,17                 Different                 from                convolutional                neural                 net-                                                                                                                     graph              to              ensure              that              the              features              of              each              node              can              be
works                         that                          perform                          effective                          feature                         extraction                          on                                                  bidirectionally             propagated.
grid-like                   data,                   GNNs                   focus                   on                  graphs                   that                   are                  non-                                                                   With               the                notations               above,                the                diagnosis                prediction
Euclidean               data.17                Studies               show               that               GNNs               have               been                                                                                                   task            can            be            deﬁned            as            follows:            Given            a            patient            visit            re-
successfully                                   applied                                   in                                   various                                   graph                                   data-based                              cord                    P /C3                      =     fx/C31    ,       x/C32     ,                     /C1/C1/C1                                                           ,       x/C3T     /C0                             1 g                         and                         medical                         ontology
tasks.14,16–19                       For              this              work,              the              most              relevant              GNN              is                                                                                 GM   ,               the               proposed               model               GNDP               generates               a               multihot
ST-GCN.14                                          ST-GCN                                          is                                          primarily                                          designed                                          for prediction             of             what             medical             codes             will             appear             in             x/C3T    .
skeleton-based                        action                        recognition                        tasks.                        It                        captures
the             features             that             are             underneath             the             spatial             conﬁgura-                                                                                                              Graph            EHR            data            construction
tion              and              temporal              dynamics              of              graph              structure              skele-                                                                                                         For           simplicity,           the           graph           construction           procedure           is           de-
ton                 data                 to                 generate                 robust                 and                 accurate                 predictions                                                                                    scribed           in           a           single-patient           case.           Given           an           EHR           data           set
of            human            actions.            However,            due            to            the            signiﬁcant            dif-                                                                                                           with                                Mjj                    unique                    medical                    codes,                    a                    knowledge                    graph
ferences                 between                 EHR                 and                 skeleton                 action                 data,                 ST-                                                                                      GM         =          (V     ,       E )              can              be              extracted              from              a              medical              ontology
GCN                cannot                be                applied                in                diagnosis                prediction                tasks                                                                                            G,                    where                   V     (jV  j      =     jM  jþjLj)                   are                    the                    node                   set                   and                   E
directly.                 The                 data                 differences                are                 due                 to                two                aspects:                                                                     the                edge                set                in                the                graph.                Then,                an                adjacency                matrix
(1)              complexity              of              the              graph              structure.              The              number              of                                                                                            A         2         RjV j    ·    jV j                   can                be                 generated                according                to                E,                where
nodes               in               EHR               data               is               signiﬁcantly               larger               than               that               in                                                                     Aij        =  1if                          (Vi  ,       Vj  )         2            E.                   For                   the                  node                   set                  V          =     fv1  ,                      /C1/C1/C1                                                           ,
skeleton                       data,                       which                       are                       at                       most                       25                       nodes                       and                       at  vjMj   ,                     /C1/C1/C1                                                           ,       vjM jþj    Lj g,          the          indexes          from          1          to        jM j          are          med-
least                     669                    nodes,                    respectively11,14;                     (2)                     the                     sparsity                     of                                                       ical         nodes         from         M         and         else         are         ancestor         codes         from       jLj.
the                      node                       attributes.                      The                      nodes’                       attributes                      of                      graph                                                Each                           node                           in                           V                           is                           encoded                           to                           a                           one-hot                           vector
EHR           data           are           more           sparse           in           both           the           spatial           and           tem-                                                                                               v/C3                       2                (0,       1)jV  j ,                   where                   the                   i-th                   element                   is                   1                   if                   i                   is                   the
poral                           domains.                           More                           detailed                           information                           can                           be                                             index              of              v/C3                                in              V.              For              the              p-th              patient              who              has              T              visit
found             in             the             Experiments             and             Evaluations             section.                                                                                                                               records                     P  p        =     fxp1    ,       xp2    ,                      /C1/C1/C1                                                           ,       xpT   g,                          each                          visit                          except                          the

GNDP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  5
last            one            is            represented           by            a            vector          xp/C3                       2         RjV j              that           is            the                                            units                   to                  extract                   the                  features                  of                  patient                   graphs                   in                   both
vector          sum          of          all          the          medical          codes          in          each          xp/C3                            and          their                                                                   spatial          and          temporal          domains.          Thus,           all           the          data          depen-
ancestors           in        GM   .           Notice           that           each           ancestor           code           is           only                                                                                                  dency,         temporal         dependency,         and         global         structure         infor-
added                      once.                      The                      generated                      multihot                      vectors                      are                      as                                               mation               can               be               exploited               by                the               model               to               learn                robust
same                    as                    the                    indexes                    of                    the                    appeared                    medical                     codes                                         patient            representation.             Figure             4             illustrates            the            details             of
and                      their                      ancestors                      in                      each                      patient.                      Different                      from                                             an                 ST-GCN                 unit.                 The                 ST-GCN                 unit                 consists                 of                 three
existing                works10–12                         that                require                medical                code                or                visit                                                                           layers.          The          ﬁrst          layer          performs           regular           two-dimensional
embedding          process,          we          directly          use          these          multihot          vec-                                                                                                                              (2D)          convolution          operation          to          expand          the          dimension          of
tors             as             the             model             input.                                                                                                                                                                           the               input               nodes’               feature.               Then,               a               graph               convolution               is
          The              last              visit           xpT                  is              taken              as              the              label              of              this              patient                                 applied            to            broadcast            the            expanded            nodes’             feature             along
and                    is                    encoded                    by                    a                     multihot                    vector                 yp            2f0,       1gjM j  .                                          with            the           graph           edges.            After            this,           feature            maps           that           con-
By                stacking               the                visit                vectors                from             xp1                  to             xp(T     /C0                             1)                  in                se-    tain                     the                     aggregation                     information                     of                     nodes                     and                     their
quence,               a               patient               visit               matrix             Pp           2         RjV j    ·       (T     /C0                             1)                 can               be                          neighbors              can             be             generated.              The             last             layer              is              similar             to
generated,               where            jV  j               is               the               size               of               a               medical               code               set                                                  the            ﬁrst            one            but             with             different            kernel            sizes.            It             performs
and                     (T        /C0                                         1)               is               the               number               of               visits.               This               matrix               con-         a            2D            convolution           operation           on            the            temporal            axis           to           ex-
tains            not            only            the            occurrence            information            of            the            med-                                                                                                      tract         temporal          information          of         the         feature          maps          from         the
ical                       codes                       from                       the                       original                       patient                       visits                       but                       also               previous          layer.          To          this          end,          a          higher         level          patient          feature
contains              the              temporal             dependency              between              each              visit.                                                                                                                  map               is               generated.              Each               ST-GCN               unit               is               followed               by               a
At                  this                  point,                  the                  patient                  visit                 records                  are                  converted                                                      channel-wise                 attention                 layer,                  to                 help                 the                  model                  focus
into                graphs                where                the                adjacency                matrix              A                represents                                                                                         on              the              channels              that              have              more              meaningful              features.20
the           invariant           structure           and           the           feature           matrix          Pp           refers                                                                                                            The              ﬁrst              two,              middle              two,              and              last              two              ST-GCN              units
to              the              occurrence              of              each              node.              Note              that              all              patients                                                                        have                     64,                     128,                    and                    256                    output                     channels,                    respectively,
from             an             EHR             data             set             share             the            same             graph             structure,                                                                                    while          each           of          them          is          followed          by          a          global          average          pool-
but             have             a             different             feature             matrix.                                                                                                                                                   ing           layer.           The           output            of            these           pooling           layers           is           concate-
                                                                                                                                                                                                                                                   nated        together         to         achieve        feature         fusion         and        generate         the
The            proposed            GNDP                                                                                                                                                                                                            ﬁnal             patient            feature             maps.             Note             that             the            outputs             of             the
The              framework              of              GNDP              is              shown              in              Figure              3.              When                                                                              ﬁrst              two              pooling              operations              are              not              passing              to              the              fol-
feeding             the            patient            visit            graphs            that            consist            of             a            patient                                                                                    lowing                   units.                   At                   the                   end                   of                   the                   model                   framework,                   a
feature             matrix             and             the             adjacency             matrix             into             GNDP,             a                                                                                               fully           connected           layer           with           a           sigmoid           activation          function
batch                  normalization                 layer                 is                  applied                 to                  normalize                  the                                                                          is           applied           to           generate           the           ﬁnal           output           for           diagnosis           pre-
input                feature                matrices.               The                following                are               six                ST-GCN                                                                                        diction.            This            model             can            be            trained            end-to-end.
                                                              FIG.            3.                                        Framework            of            GNDP.            ST-GCN,            spatial-temporal            graph            convolutional            network.

6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    LI           ET           AL.
                                                                                                                                                                                                      FIG.            4.                                        Details            of            an            ST-GCN            unit.
Spatial            graph            convolution                                                                                                                                                                                                                                                   The            spatial            graph            convolution            process            can            be            formally
For           simplicity,           the           spatial           graph           convolution           operation                                                                                                                                                                               described             as             follows:
is             explained             in             a             single             patient             with             a             single             visit             case.                                                                                                                                                                                                                       x¢=    +Wcnn        /C1                   x     þ     b                                                                                                                                                                                                                                                                                                                                                                                      (3)
Taking                   adjacency                    matrix                A         2         RjV j    ·    jV j                      and                    a                    patient
visit         vector       x         2         RjV  j    ·     1           as         the         inputs,         an         effective         and         ef-                                                                                                                                                                                                                     GCNout    (x¢)      =          ~A       /C10                                x¢       /C10                                Wgcn                                                                                                                                                                                                                                                                                (4)
ﬁcient                graph               convolution               can               be                achieved                by                the               fol-
lowing             function             that             is             deﬁned             by             GCN            19:                                                                                                                                                                      and
                                                                                                                                           1                                                    1
                                                                GCNout    (x)      =     D   /C0                                           2  (A     þ     I)D   /C0                            2 xWgcn                                                                                                                                                                                                    (1)~                         1                                                    1
                                                                                                                                                                                                                                                                                                                                                                                                     A      =     D   /C0               2  (A     þ     I)D   /C0                            2                                                                                                                                                                                                                                                                                                                                                                      (5)
and
                                                                                                         Dii        =        +                                                                                                                                                                    Temporal            dependency            modeling
                                                                                                                                     j                          (Aij       þ      Iij)(2)                                                                                                         When             given            a             patient             who             has            T             visit            records,             the             fea-
                                                                                                                                                                                                                                                                                                  ture              matrix             is             formed              by             concatenating             the             T        /C0                                         1              visit
where               D         2         RjV j    ·    jV j                    is                 the                  degree                  matrix                 of                 the                  input                                                                                vectors         together         in         sequential         order,         and         the         T-th         vector
graph,               I         2         RjV j    ·    jV j                     is                  the                  identity                  matrix                  referring                  to                                                                                          is            the            prediction            label.           This            equals            to            assigning            a            T        /C0                                         1
the              self              connections              of              each              nodes,              and           Wgcn           2         R1    ·    jV j                                                                                                                          dimensional              vector               that              carries              the               temporal               informa-
represents            a            learnable            weight            matrix.                                                                                                                                                                                                                 tion                 for                every                 node                in                the                graph.                 Thus,                 the                temporal
            In          practice,          the          input          feature          of          a         single          visit         x         can          be                                                                                                                             axis         is         well-ordered         with         a         constraint         length         for         individ-
represented                       by                       a                       2D                       tensor                       of                                (jV  j,       1)                       dimensions,                                                                     ual           patients.           This           provides           a           possibility          to           deﬁne           a           sim-
where            jV  j               represents               the               amount               of               nodes               in               the               pa-                                                                                                                  ple                 convolutional                  operation                 to                 extract                 features                 in                 the
tient                 graph                 and                 1                 is                 the                 dimension                 of                 node                 features.                                                                                              temporal                     domain.                     Formally,                     the                     patient                     feature                     ma-
By                   performing                   standard                   2D                   convolution                   with               j1      ·       1j                                                                                                                             trix                  Pp           2         RjV j    ·       (T     /C0                             1)                        can                      be                     represented                     as                     a                      three-
kernel                           size                           and                                      (1,       1)                           stride                           on                           the                           input                           tensor,               dimensional                           tensor                           with                                     (jV  j,       T        /C0                                         1,       1)                           dimensions,
which                   equals                   to                   multiply                   the                   input                   with                   a                   learnable                                                                                               where          jV  j             is             the             size             of             the             node             set,             T        /C0                                         1             is             the             total
weight                     matrix                 Wcnn           2          Rd     ·     d                        and                     adds                     a                     bias                     vector                                                                          visits,                 and                 1                 is                 the                 dimension                 of                 node                 features.                 After
b         2          Rd  ,                a                new                 tensor             x¢                with                the                shape                of                       (jV  j,       d )                is                                                      the               ﬁrst               convolution               layer               of               an               ST-GCN               unit,               a               new
generated.             This             step             equals             to             map             the             low             dimension                                                                                                                                              tensor             with                  (jV  j,       T        /C0                                         1,       d  )             dimensions             is             generated.             By
of                         node                         features                         to                         the                         higher                         space                         by                         learnable                                                 reshaping             the             tensor              to                   (jV  j,       d ,       T        /C0                                         1)              and             performing
weights            to            enrich            the            features.            Then,            the            graph            convo-                                                                                                                                                    graph              convolution              on              the              ﬁrst              and               second              dimension,
lution               is               implemented               in               the               matrix               multiplication               of~                 and         the         new         tensor.                                                                              a                 tensor                 with                the                 same                shape                is                 generated.                 Note                 that
the         normalized         adjacency         matrix       A                                                                                                                                                                                                                                   this               step               expands               the               dimension               of               node               features               and

GNDP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  7
aggregates                    them                    on                    the                    ﬁrst                     two                    axes                    of                    the                    tensor                        sign                 a                 strategy                 to                 divide                 the                 graph                 structure                 of                 EHR
where         the         temporal         axis         remains         unchanged.         Therefore,                                                                                                                                                 data             into             four             subsets:             (1)             from             the             leaf             nodes             to             their
inspired          by         ST-GCN,14         the          whole         spatial-temporal          con-                                                                                                                                              second-level                     ancestors;                     (2)                     from                     ﬁrst-level                     ancestors
volution            operation            can             be            deﬁned             as            follows:                                                                                                                                      to         third-level         ancestors;         (3)         from         second-level         ancestors
                                                                                            jV   j/C0                          1T     /C0                          2                                                                                  to              fourth-level              ancestors;              and               (4)               from              third-level               an-
                                   P¢(jV j,    T     /C0                          1,    d )        =                      +                                                                                                                           cestors             to             the             root             code.             To             achieve             this,             four             new             ad-
                                                                                                    0                                 +0                         Wcnn        /C1                   P(/C3                   ,   /C3                   ,    1)      þ     bgcn                                                                                        (6)jacency                                                matrices                                       fA1  ,     A2  ,      A3  ,      A4 g2         RjV j    ·    jV j                                                   are
                                                                                                                                                                                                                                                      created              based             on           GM                 and              the             partition              strategy             above.
                                                                                                                                    T     /C0                          2                                                                              We            assign           different            edge            weights           in           the            four           new           adja-
           PGCN         =      GCNout    (P¢(jV j,    T     /C0                          1,    d )  )      =                +                        A       /C10                                P¢(jV j,   /C3                   ,    d )        /C10                                Wgcn~
                                                                                                                                          0                                                                                                           cency            matrices            according            to            which            subset            they            belong.
                                                                                                                                                                                                                               (7)                    Thus,                 the                 differences                 between                 each                 node                 level                 in                 the
                                                                                                                                                                                                                                                      graph                       can                       be                       learned                       by                       the                       proposed                       model.                       For
                                                                                              jV   j/C0                          1d    /C0                          1                                                                                 implementation,                the                four                new                adjacency                matrices                are
PTCN         =      TCNout    (PGCN     )      =                      +                                                                                                                                                                               represented             by             a             tensor             with                  (4,     jV  j,     jV  j)             dimensions.
                                                                                                      0                               +0                        Wtcn        /C1                PGCN  (/C3                   ,    T     /C0                          1,   /C3                   )      þ     btcnThe          reasons           for          using          subgraphs           instead          of          the           whole
                                                                                                                                                                                                                               (8)                    structure         are         twofold.         First,         the         subgraph         will         restrict         the
          After                     six                     spatial-temporal                     convolution                     operations,                                                                                                          broadcast              of              node              information             more              locally              when              per-
the             ﬁnal             feature             maps             are             deﬁned             as             follows:                                                                                                                      forming                  graph                 convolution                  operations.                  Therefore,                  the
              Pfinal        =         [F     pooling     (PTCN  2  ),     F    pooling     (PTCN  4  ),     F     pooling     (PTCN  6  )]                                                                                                            local          differential          properties          of          the          whole          graph          structure
                                                                                                                                                                                                                               (9)                    can           be           captured           by           the           model.           Meanwhile,           the           node           in-
                                                                                                                                                                                                                                                      formation               can               still               be               transferred               globally               through               the
where           F     pooling     (       /C1                              )              is              the              global              average              pooling              opera-                                                       common                     nodes                     from                     a                     different                     subset.                     Second,                     the
tion.                 After                 a                 fully                 connected                 layer,                 the                 output                 of                 the                                                computational              consumption              of              performing              graph              con-
GNDP             is             deﬁned             as             follows:                                                                                                                                                                            volution          on          subgraphs          is          less          because          the          adjacency          ma-
                                                                                                                                                                                                                                                      trices                  of                 subgraphs                  are                 more                  sparse                 than                 the                  original
                                                                           ^y     =      Sigmoid (FCN    (Pfinal   ))                                                                                                                                                                                                                                                                                          (10)graph.            The            effectiveness            of            our            partition            strategy            is           ver-
where                   ^y         2                (0,       1)jM j                      is                    the                    multihot                   prediction                    result.                                               iﬁed            in            the            Experiments            and            Evaluations            section.
Note            that            the            dimension            of            ^y            is            the            size            of            the            medical
code             set             M,             which             is             as             same             as             the             label           y.                                                                                    Experiments           and           Evaluations
                                                                                                                                                                                                                                                      Data            description
Objective            function                                                                                                                                                                                                                         We               use               two               real-world               medical               data               sets               in               the               experi-
The                 diagnosis                 prediction                 is                 a                 multilabel                 classiﬁcation                                                                                                ments                        to                        examine                        the                        performance                        of                        the                        proposed
task,                               and                               therefore,                               GNDP                               applies                               binary                               cross-                   model              in              the             diagnosis              prediction              task.              Data              set-I              is              the
entropy               loss               as               the               objective               function               to               optimize               the                                                                                third            version            of            Medical            Information            Mart            for            Intensive
loss                    between                    the                    ground                    truth                    multihot                   label                 y                    and                                                Care,x           a            public            accessible            benchmark            data            set            for            critical
the             model             prediction             ^y             as             follows:                                                                                                                                                       care                             that                             has                             been                             widely                             applied                             in                             a                             variety                             of
                                                                i    =   jM j/C0                          1                                                                                                                                           researches.8,10–12,21                      Data                set-II               is                a               private                data               set                that
 L(^y,     y)      =          /C0                    1                                                                            yi  )     þ        (1     /C0                                     yi  )      /C3                                       log         (1     /C0                                   ^yi  ))is           constructed           from            a           real-world            longitudinal           EHR           data-
                                                jM j                             +i    =    0                                                          (yi        /C3                                       log         (^                            base.         The         medical         events         from        both         data         sets         are         encoded
                                                                                                                                                                                                                           (11)                       following           the            ICD            coding            system.            Table            1            shows            the            de-
                                                                                                                                                                                                                                                      tails              of              the              two              data              sets.              It              can              be              seen              that              Data              set-II
Graph            partition            strategy                                                                                                                                                                                                        contains               more               patients               and               each               patient               has               more               visit
The             graph            convolution            operation             deﬁned             in            1            is             equal                                                                                                      records.          However,           the           average           medical          events           of           an           indi-
to         computing        the         inner        product         between         each         node        fea-                                                                                                                                    vidual            visit            in            Data            set-II            are            signiﬁcantly            less            than            Data
ture            vector           and            a            shared           weight            vector,           which           may            ne-                                                                                                  set-I.             Therefore,             Data             set-I             is             more             challenging             in             train-
glect          the          local          properties          of          the          graph          structure.14          Since                                                                                                                    ing             the              deep             models              for              diagnosis              predictions.
the               graph               EHR               data               are               constructed               in               a               hierarchical                                                                                             We              follow              the              initial              data              process              procedure              devel-
structure,            nodes            at            different            levels            should           have            distinct                                                                                                                 oped                      by                      Choi                      et.al.8                      to                      create                      time-ordered                      patient
weights.             To             unfold             this             property             to             the             model,             we             de-                                                                                     xhttps://mimic.physionet.org/

8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    LI           ET           AL.
Table          1.                Statistics          of          the         data          sets                                                                                                                                                                                                                        Table          2.                Statistics          of          the          graphs
                                                                                                                                                                                               Data         set-I                                                                     Data         set-II                                                                                                                                                                                                                                                                                Graph          in
                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Graph-I                                                                    Graph-II                        ST-GCN14
No.         of         patients                                                                                                                                                                                                                                                                                                                                                                                                                                                                                7499                                                                                                                                   14,060
No.         of         visits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                19,911                                                                                                               258,140No.         of         nodes         in         graph                                                                                                                                                                                                                      5550                                                                                                               5572                                                                                                                                           25
Average         no.         of         visits         per         patient                                                                                                                                                                                                                                        2.67                                                                                                                                                18.36No.         of         edges         in         graph                                                                                                                                                                                                                       5564                                                                                                               5513                                                                                                                                           24
No.         of         unique         ICD9         codes                                                                                                                                                                                                                                                                                                                           4880                                                                                                                                              4914No.         of         leaf         nodes         in         graph                                                                                                                                                           4880                                                                                                               4914                                                                                                                                                    –
Average         no.         of         ICD9         codes         per         visit                                                                                                                                                                                    13.06                                                                                                                                                3.28No.         of         ancestor         nodes         in         graph                                                                                                         670                                                                                                                               658                                                                                                                                                    –
Maximum         no.         of         ICD9         codes         per         visit                                                                                                                                                                                39                                                                                                                                                                                23No.         of         level         4         ancestor         nodes                                                                                                                                                   15                                                                                                                                                15                                                                                                                                                    –
No.         of         category         codes                                                                                                                                                                                                                                                                                                                                                                                      171                                                                                                                                                               154No.         of         level         3         ancestor         nodes                                                                                                                                   130                                                                                                                               130                                                                                                                                                    –
Average         no.         of         category         codes         per         visit                                                                                                                              10.16                                                                                                                                                2.68No.         of         level         2         ancestor         nodes                                                                                                                                   323                                                                                                                               334                                                                                                                                                    –
Maximum         no.         of         category         codes         per         visit                                                                                                                         30                                                                                                                                                                                13No.         of         level         1         ancestor         nodes                                                                                                                                   202                                                                                                                               179                                                                                                                                                    –
           ICD,         International         Classiﬁcation         of         Diseases.                                                                                                                                                                                                                                          ST-GCN,         spatial-temporal         graph         convolutional         network.
sequences           for           each           data           set,           and           patients           who           have           less                                                                                                                                                                                                 agnose                    prediction                    task.                    Thus,                    we                    take                    the                    uni-
than                  two                  visits                  are                  removed.                  After                  this,                  an                  exclusive                                                                                                                                                     labeling              partition              strategy,              which              is              equivalent              to
knowledge              graph              for             each              data              set             can              be              constructed                                                                                                                                                                                        compute                   the                   inner                   product                   between                   the                   weight
for                 the                 CCS                 medical                 ontology,                 which                 is                 also                 used                 in                                                                                                                                               vector                  and                 the                  feature                 vector                  of                  all                  neighboring
previous         works.11–13                  As         shown         in          Table         2,         the          structure                                                                                                                                                                                                                nodes.14              We              also              adopt              ST-GCN+,              which              adopts
and               the               size               of               each               constructed               graph               are               nearly               the                                                                                                                                                               our             partition             strategy             as             a             baseline.
same                    and                    both                    them                    are                    signiﬁcantly                   complex                    than                                                                                                                                                GCN.19                        GCN,                        which                        is                        developed                        by                        Kiptf                        and
the             graph             applied             in             ST-GCN.14                                                                                                                                                                                                                                                                    Welling,              is               considered              to              be              one               of              the              strongest
             It         has         been         discussed         in         previous         works         that,         in         prac-                                                                                                                                                                                                       baselines           for            graph            convolutional            networks.22            We
tice,                 predicting                the                 category                 of                 each                 medical                 event                 is                                                                                                                                                             follow             the             data             prepossessing             method             introduced
enough        for         preserving        sufﬁcient        granularity        for        each        di-                                                                                                                                                                                                                                        in         Choi         et         al.12         and         Kipf         and         Welling19         and         fed         the
agnosis.11,12          Therefore,         we         implement         category         diagno-                                                                                                                                                                                                                                                   data              into              a             two-layer             GCN              model.              Note             that             this
sis                prediction                by                replacing                the                actual                diagnosis                codes                                                                                                                                                                                   model                   is                   incapable                   of                   learning                   the                   time                   depen-
from             the             target             visit             of             each             patient             to             the             code             in             the                                                                                                                                                      dency             of             the             input             data.
second             hierarchy             of             ICD-9             as             the             category             label.                                                                                                                                                                                                Dipole.10               Dipole               is               an               attention-based               bidirectional
                                                                                                                                                                                                                                                                                                                                                  recurrent                 neural                 network,                 and                 it                 takes                 the                 same
Baseline            method                                                                                                                                                                                                                                                                                                                        raw               input               as               GRAM.               We               implement               the               Dipolel
To         examine         the          performance         of         the          proposed         approach                                                                                                                                                                                                                                     version          as          given          in          Ma          et          al.,10          which          is          based          on          a
GNDP,            we            conduct            comparative            experiments            with            the                                                                                                                                                                                                                               location-based             attention             mechanism.
following             baseline             models:                                                                                                                                                                                                                                                                                  GRAM.12            GRAM            is            the            pioneering            work            that            uses            a
                                                                                                                                                                                                                                                                                                                                                  medical                     knowledge                     graph                     associated                     with                     EHR
             GNDP_.         GNDP_         removes         our         partition         strategy         and                                                                                                                                                                                                                                      data           to           learn           the           medical           code           representations           via
                           performs                       graph                       convolution                       operations                       with                       a                                                                                                                                                             attention            mechanisms            and            RNNs.            We            implement
                           single             adjacency             matrix.                                                                                                                                                                                                                                                                       the             GRAM     þ                     version,12             which             utilizes             an             initial-
             GNDPa.                  GNDPa                  is                  the                  backbone                  of                  the                  proposed                                                                                                                                                                  ized                   embedding                   matrix                   with                   original                   input                   visit
                           model                   but                    without                   feature                    fusion                    and                    channel-                                                                                                                                                          sequences                 to                 generate                 medical                 code                 embeddings
                           wise             attention.                                                                                                                                                                                                                                                                                            and                       feeds                        it                       into                       a                       single                       hidden                        layer                       Gated
             GNDPb.                   GNDPb                   removes                   the                   channel-wise                   atten-                                                                                                                                                                                               Recurrent             Unit             (GRU).23
                           tion                layers                behind                each                ST-GCN                unit                in                 GNDP                                                                                                                                                    KAME.11         KAME         shares         the         framework         with         GRAM;
                           and               keeps                the               average               pooling               layers               to               perform                                                                                                                                                                     we             implement             this             model             by             using             a             supplemen-
                           feature             fusion.                                                                                                                                                                                                                                                                                            tary            branch            that            generates             knowledge            vector,            and
             GNDPc.          GNDPc          removes           the          global          average          pooling                                                                                                                                                                                                                               then                          concatenate                          the                          output                          with                          the                          hidden
                           layers                 in                 the                 second,                 fourth,                 and                 sixth                 ST-GCN                                                                                                                                                         vector,                         which                         is                         generated                         by                         the                         GRU                         from
                           unit             in             GNDP             and             keeps             the             attention             layers.                                                                                                                                                                                       GRAM             before             the             last             classiﬁcation             layer.
             ST-GCN.14               ST-GCN               uses               different               partition               strate-                                                                                                                                                                                                CAMP.13              CAMP               is               a               recent               work               that               uses               not               only
                           gies              to              divide              the              input              graph              into              different              sub-                                                                                                                                                             the          medical          ontology          but          also          patient          demographics
                           sets             to             enhance             the             model              performance              in             action                                                                                                                                                                                  to               perform               diagnosis               prediction.               The               patient               de-
                           recognition             tasks,             which             are             not             applicable             to             di-                                                                                                                                                                                 mographics               consist               of               age               and               gender.               However,

GNDP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  9
Table          3.                Results          of          ablation          experiments
                                                                                                                                                                                     Code-level          Accuracy@K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Visit-level          Precision@K
Data         set                                                                           Model                     5                                                                                                                  10                                                                                                          15                                                                                                          20                                                                                                          25                                                                                                          30                                                                                                                  5                                                                                                                  10                                                                                                          15                                                                                                          20                                                                                                          25                                                                                                          30
Data         set-I                                            GNDP                                                                            0.3432                                        0.5401                                        0.6701                                        0.7571                                        0.8176                                        0.8629                                        0.7433                                        0.6766                                        0.7182                                        0.7811                                        0.8338                                        0.8749
                                                      GNDP_                                                                     0.3337                                                     0.5338                                                    0.6625                                                     0.7498                                                    0.8127                                                     0.8603                                                    0.7291                                                     0.6704                                                     0.7115                                                    0.7754                                                     0.8295                                                    0.8721
                                                      GNDPb                                                                        0.3331                                                     0.5257                                                    0.6530                                                     0.7431                                                    0.8082                                                     0.8558                                                    0.7275                                                     0.6605                                                     0.7013                                                    0.7669                                                     0.8248                                                    0.8679
                                                      GNDPc                                                                           0.3294                                                     0.5188                                                    0.6493                                                     0.7364                                                    0.7983                                                     0.8473                                                    0.7203                                                     0.6538                                                     0.6990                                                    0.7626                                                     0.8171                                                    0.8616
                                                      GNDPa                                                                         0.3082                                                     0.5058                                                    0.6333                                                     0.7228                                                    0.7847                                                     0.8303                                                    0.7077                                                     0.6420                                                     0.6805                                                    0.7460                                                     0.8004                                                    0.8407
                                                      ST-GCN+                                              0.2933                                                     0.4901                                                    0.6095                                                     0.6890                                                    0.7434                                                     0.8051                                                    0.6994                                                     0.6349                                                     0.6711                                                    0.7273                                                     0.7782                                                    0.8205
                                                      ST-GCN                                                               0.2801                                                     0.4722                                                    0.5895                                                     0.6802                                                    0.7364                                                     0.7993                                                    0.6922                                                     0.6204                                                     0.6619                                                    0.7187                                                     0.7737                                                    0.8147
           The         values         in         bold         are         the         best         results         in         this         experiment.
           GNDP,         Graph         Neural         Network-Based         Diagnosis         Prediction.
                            this                   information                   is                   only                   available                   in                   Data                   set-I.                                                                                                                                We                     tune                     k                     from                     5                     to                     30                     to                     evaluate                     the                     coarse-
                            Therefore,                  we                  implement                  CAMP_                  that                  removes                                                                                                                                                                  grained               and               ﬁne-grained               performance               of               each               model,
                            the          patient          demographic          attention          branch          in          Data                                                                                                                                                                                           and             the             greater             value             indicates             a             better             performance.
                            set-II.
              RNN.            We            use            a            one-directional            GRU23            to            model            the                                                                                                                                                                       Implementation            detail
                            EHR                     sequence                     as                     a                     baseline                     for                     all                     the                     models                                                                                    We         implement         all         the         aforementioned         approaches         with
                            above.                                                                                                                                                                                                                                                                                           PyTorch**          1.0.          All          training          processes          are          accomplished
                                                                                                                                                                                                                                                                                                                             via          two          Nvidia           Titan          V           GPU          and          CUDA          9.0          with          Inter
Evaluation            metric                                                                                                                                                                                                                                                                                                 Core         i9-7900x         processor.         We         split         the         data         sets         into         dif-
We               evaluate               the               performance               of                all               baseline               methods                                                                                                                                                                       ferent                   ratios                    to                   evaluate                   the                    performance                   of                   GNDP.
and                     the                     proposed                    method                    by                     using                    visit-level                    preci-                                                                                                                                  First,             the            data             sets             are             randomly             divided             into             training,
sion@k             and             code-level            accuracy@k             as             same             as             previous                                                                                                                                                                                      validation,               and                testing                set                in                a               0:75           :            0:10           :            0:15                ratio
works11,12             to             provide             multigrained             measurements.                                                                                                                                                                                                                             for                  10                  times                  as                  same                  as                  existing                  methods.11–13                          Then
              Visit-level             precision@k             measures              the             prediction             pre-                                                                                                                                                                                              the             ratio             of             the             testing             set             is             increased             to             0:30             and             the
cision                       of                       individual                       visits                       within                      patient                      sequences.                                                                                                                                      ratio            of            the            training            set            is            decreased            to            0:60.            The            regu-
For                     a                     single                     visit,                     the                     ﬁnal                     output                     of                     our                     model                     is                                                                  larization          (l2          norm          with          the          coefﬁcient          0                      :3      ·       10   /C0                             5  )          and
^                                                                                                                                                                                                                                                                                                                            dropout                strategies                (the                dropout                rate                is                0.25)                are                used
y       =          [^y1  ,      ^y2  ,                     /C1/C1/C1                                                           ,      ^yjM j   ],                     where                    ^y           2RjM j ,                      and                     the                     grand                              for                               training                               GNDP.                               The                               learning                               rate                               is                               set                               to
truth                      label                      is                      y       =         [y1  ,       y2  ,                      /C1/C1/C1                                                           ,       yM    ],                      where                      y/C3                          2f0,       1g.    0:45      ·       10   /C0                             3                   initially                 and                 decay                 10%                 for                 every                 10                 ep-
The             visit-level             precision@k             is             deﬁned             as             follows:                                                                                                                                                                                                    ochs.           For           other           baseline           models,           the           model           parameters
                                                                      visitlevel      /C0                                     precision@k     =                                                         j^ycorrect  jk                                                                                                       are             set             as             same             as             their             proposals.
                                                                                                                                                                                                     min(k,     Y  )                                                                                                                                                                   (12)
where             j^ycorrect  j                denotes                the                number                of                correct                predic-                                                                                                                                                              Result            and            evaluation
tions             among             the             top-k             outputs             of            ^y,             which             are             ranked                                                                                                                                                             We           examine           the           effectiveness           and           necessity           of           the           pro-
by               their               probability,               and            Y                 is               the               number               sum               of               the                                                                                                                              posed                  components                  in                  GNDP,                  and                  in                  the                  meanwhile
positive             labels             (yi        =       1)             in             the             target             visit.             Code-level             ac-                                                                                                                                                    making             comparisons             with             the             most             related             model             ST-
curacy@k               measures               the               overall               accuracy               of               the               model                                                                                                                                                                        GCN                          in                          diagnosis                          prediction                          tasks                          on                          Data                          set-I.
predictions.               For               multiple               patient               sequences,               the               code-                                                                                                                                                                                   Table                 3                 shows                 the                code-level                 accuracy                 and                 visit-level
level             accuracy@k             is             deﬁned             as             follows:                                                                                                                                                                                                                           precision                with                different                k               values                under                the               split                ratio
                                                                                                                                                                                                                                                                                                                             of                      0:75           :            0:10           :            0:15.                     Compared                      with                      ST-GCN+,                      the
                                                                                                                                                                                                   jPj                                                                                                                       code-level                        accuracy                         and                         the                         visit-level                        precision                         of
                                                                                                                                                                                                   +                 ycorrect  jk                                                                                            GNDP                                improve                          4:99%                                and                          4:39%,                                respectively,
                                                                codelevel      /C0                                     precision@k     =                                                         i    =    1     j^                                                                       (13)
                                                                                                                                                                                                                jPj                                                                                                          when                k      =       5,                 and                 improve             5:78%                and             5:44%,                respec-
                                                                                                                                                                                                                +                                                                                                            tively,                      when                     k      =       30.                      As                      aforementioned,                      ST-GCN                      is
                                                                                                                                                                                                              i    =    1     jY j
                                                                                                                                                                                                                                                                                                                             designed                                             for                                             skeleton-based                                             action                                             recognition.
where             P             indicates             the             total             number             of             patients.                                                                                                                                                                                          **https://pytorch.org/

10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               LI           ET           AL.
Table          4.                Results          of         comparative          experiments-I
                                                                                                                                                                                                                                 Code-level          Accuracy@K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Visit-level          Precision@K
Data         set                                                                               Model                                              5                                                                                                                  10                                                                                                          15                                                                                                          20                                                                                                          25                                                                                                          30                                                                                                                  5                                                                                                                  10                                                                                                          15                                                                                                          20                                                                                                          25                                                                                                          30
Data         set-I                                                    GNDP                                                                     0.3432                                        0.5401                                        0.6701                                        0.7571                                        0.8176                                        0.8629                                        0.7433                                        0.6766                                        0.7182                                        0.7811                                        0.8338                                        0.8749
                                                                     CAMP                                                                             0.3225                                                    0.5173                                                     0.6489                                                    0.7285                                                     0.7933                                                    0.8457                                                    0.7219                                                     0.6680                                                    0.7074                                                     0.7623                                                    0.8219                                                     0.8541
                                                                     CAMP_                                                             0.3188                                                    0.5074                                                     0.6401                                                    0.7253                                                     0.7870                                                    0.8411                                                    0.7139                                                     0.6630                                                    0.7010                                                     0.7523                                                    0.8129                                                     0.8453
                                                                     KAME11                                                       0.3167                                                    0.5100                                                     0.6379                                                    0.7240                                                     0.7862                                                    0.8303                                                    0.7103                                                     0.6568                                                    0.6967                                                     0.7562                                                    0.8091                                                     0.8470
                                                                     GRAM11                                                  0.3123                                                    0.5026                                                     0.6296                                                    0.7142                                                     0.7798                                                    0.8266                                                    0.6698                                                     0.6447                                                    0.6847                                                     0.7439                                                    0.8007                                                     0.8424
                                                                     Dipole11                                              0.2774                                                    0.4556                                                     0.5801                                                    0.6671                                                     0.7354                                                    0.7902                                                    0.6220                                                     0.5839                                                    0.6310                                                     0.6912                                                    0.7542                                                     0.8017
                                                                     RNN11                                                                          0.276                                                                     0.4548                                                     0.5751                                                    0.6647                                                     0.7350                                                    0.7867                                                    0.6158                                                     0.5803                                                    0.6243                                                     0.6912                                                    0.7542                                                     0.8017
                                                                     GCN                                                                                                  0.2465                                                    0.3902                                                     0.4909                                                    0.5941                                                     0.6790                                                    0.7317                                                    0.5526                                                     0.5328                                                    0.5751                                                     0.6249                                                    0.7011                                                     0.7324
Data         set-II                                            GNDP                                                                     0.6539                                        0.8033                                        0.8633                                        0.9028                                        0.9242                                        0.9429                                        0.6924                                        0.8251                                        0.8804                                        0.9142                                        0.9322                                        0.9490
                                                                     CAMP_                                                             0.6015                                                    0.7611                                                     0.8410                                                    0.8772                                                     0.9052                                                    0.9295                                                    0.6635                                                     0.8007                                                    0.8587                                                     0.9013                                                    0.9197                                                     0.9402
                                                                     KAME                                                                                0.6005                                                    0.7602                                                     0.8331                                                    0.8753                                                     0.9045                                                    0.9249                                                    0.6618                                                     0.7934                                                    0.8561                                                     0.8923                                                    0.9181                                                     0.9353
                                                                     GRAM                                                                           0.5716                                                    0.7533                                                     0.8285                                                    0.8746                                                     0.9062                                                    0.9227                                                    0.6460                                                     0.7855                                                    0.8267                                                     0.8908                                                    0.9181                                                     0.9321
                                                                     Dipole                                                                      0.5756                                                    0.6893                                                     0.7640                                                    0.8102                                                     0.8481                                                    0.8828                                                    0.6376                                                     0.7418                                                    0.8049                                                     0.8430                                                    0.8721                                                     0.9001
                                                                     RNN                                                                                                   0.5677                                                    0.6814                                                     0.7525                                                    0.8011                                                     0.8403                                                    0.8769                                                    0.6366                                                     0.7401                                                    0.7932                                                     0.8344                                                    0.8528                                                     0.8970
                                                                     GCN                                                                                                  0.5112                                                    0.5726                                                     0.6433                                                    0.7201                                                     0.7317                                                    0.7512                                                    0.5526                                                     0.5328                                                    0.5751                                                     0.6249                                                    0.7011                                                     0.7324
              The         values         in         bold         are         the         best         results         in         this         experiment.
              CAMP,         co-attention         memory         networks         for         diagnosis         prediction;          GRAM,         graph-based         attention         model;         KAME,         knowledge-based          attention         model;
RNN,         recurrent         neural         network.
Compared                 with                 the                 graph                 structure                 patient                 data,                 the                                                                                                                                                                                                                                       of              0:75           :            0:10           :            0:15.             From             Table              4,             it              can             be             observed
skeleton                     data                      have                      signiﬁcantly                     denser                      time                      stamps                                                                                                                                                                                                                            that                             knowledge-guided                             models,                            which                            are                             GNDP,
(i.e.,            >300             on              Kinetics             data              set14)              and              a              much             simpler                                                                                                                                                                                                                                    GRAM,                       KAME,                       and                       CAMP,                       achieve                       better                       perfor-
structure.          Thus,          it          is          more          challenging          to          model          patient                                                                                                                                                                                                                                                                          mance               on               both               data               sets               than               nonknowledge               models.
graphs.           The           results           suggest           that           our           proposed           model           is                                                                                                                                                                                                                                                                    These                    results                    suggest                    that                    the                    utilization                    of                    medical
more            effective            to            model            sparse            and            complex           EHR            data                                                                                                                                                                                                                                                                knowledge             can             effectively             increase             the             performance             of
than                  ST-GCN.                  Compared                 with                  ST-GCN,                 the                  perfor-                                                                                                                                                                                                                                                        diagnosis                   prediction                    model.                   However,                   the                    code-level
mance             of             ST-GCN    þ                    is             better,             and             meanwhile,             GNDP                                                                                                                                                                                                                                                            accuracy               and               visit-level              precision               of              Dipole               and               RNN
outperforms             GNDP_.             These              results             conﬁrm              the             effec-                                                                                                                                                                                                                                                                              are            signiﬁcantly            higher           than            GCN,            which           performs            di-
tiveness               of               the               graph               conﬁguration               partitioning               strat-                                                                                                                                                                                                                                                                agnosis                    prediction                    on                    the                    knowledge                    graph                    directly.
egy.               The               following               results               show               that               each               component                                                                                                                                                                                                                                                     The            reason            is            that            GCN            only            uses            the            spatial            informa-
of          the          proposed          GNDP          contributes          to          increase          the          pre-                                                                                                                                                                                                                                                                             tion         from         knowledge         graph         and         is         unable         to         capture         the
cision          and          accuracy.          Especially,          when          removing          feature                                                                                                                                                                                                                                                                                              time             sequence             information.            This             implies             that            the            tem-
fusion              in              GNDP             (i.e.,              the              global              average              pooling             layer                                                                                                                                                                                                                                              poral         features        of        EHR        data        are         crucial        for        predicting         pa-
behind                the                second,                fourth,                and                sixth                unit),                the                code-                                                                                                                                                                                                                             tients’             future             information.
level          accuracy          drops          1:38%          and          the          visit-level          precision                                                                                                                                                                                                                                                                                                    For                                    knowledge-guided                                    models,                                    compared                                    with
drops             2:30%             when             k      =       5.                                                                                                                                                                                                                                                                                                                                    CAMP,                     GNDP                     improves                     the                     code-level                     accuracy                     in
                 We            apply           Data           set-I           and            Data           set-II           to           compare           our                                                                                                                                                                                                                                           2:07%,2:12%,1:72%             when             k      =       5,       15,       30,             and             improves
model              against              SOTA              approaches              under              the              split              ratio                                                                                                                                                                                                                                                            the                                 visit-level                                 precision                                 in                                 2:14%,1:08%,2:08%
Table          5.                Results          of         comparative          experiments-II
                                                                                                                                                                                                                             Code-level          Accuracy@K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Visit-level          Precision@K
Data         set                                                                         Model                                               5                                                                                                                   10                                                                                                           15                                                                                                           20                                                                                                           25                                                                                                           30                                                                                                                   5                                                                                                                   10                                                                                                           15                                                                                                           20                                                                                                           25                                                                                                           30
Data         set-I                                                     GNDP                                                        0.3400                                         0.5387                                         0.6642                                         0.7520                                         0.8146                                         0.8606                                         0.7378                                         0.6754                                         0.7121                                         0.7760                                         0.8310                                         0.8725
                                                                      CAMP                                                               0.3175                                                      0.5084                                                      0.6425                                                      0.7269                                                      0.7902                                                      0.8400                                                      0.7211                                                      0.6649                                                      0.7046                                                      0.7537                                                      0.8151                                                      0.8435
                                                                      CAMP_                                              0.3139                                                      0.5062                                                      0.6401                                                      0.7167                                                      0.7813                                                      0.8326                                                      0.7105                                                      0.6581                                                      0.6992                                                      0.7500                                                      0.8030                                                      0.8409
                                                                      KAME                                                                 0.3117                                                      0.5028                                                      0.6296                                                      0.7211                                                      0.7822                                                      0.8248                                                      0.7057                                                      0.6494                                                      0.6910                                                      0.7530                                                      0.8049                                                      0.8380
                                                                      GRAM                                                            0.3041                                                      0.4976                                                      0.6217                                                      0.7123                                                      0.7737                                                      0.8206                                                      0.6647                                                      0.6447                                                      0.6847                                                      0.7392                                                      0.7913                                                      0.8327
Data         set-II                                             GNDP                                                        0.6510                                         0.7978                                         0.8631                                         0.8975                                         0.9229                                         0.9376                                         0.6866                                         0.8244                                         0.8768                                         0.9067                                         0.9226                                         0.9358
                                                                      CAMP_                                              0.5948                                                      0.7595                                                      0.8377                                                      0.8718                                                      0.9034                                                      0.9288                                                      0.6558                                                      0.7983                                                      0.8515                                                      0.8961                                                      0.9119                                                      0.9329
                                                                      KAME                                                                 0.5998                                                      0.7544                                                      0.8311                                                      0.8741                                                      0.8929                                                      0.9241                                                      0.6573                                                      0.7932                                                      0.8496                                                      0.8921                                                      0.9163                                                      0.9305
                                                                      GRAM                                                            0.5669                                                      0.7512                                                      0.8204                                                      0.8726                                                      0.8957                                                      0.9167                                                      0.6408                                                      0.7833                                                      0.8230                                                      0.8826                                                      0.9112                                                      0.9238
              The         values         in         bold         are         the         best         results         in         this         experiment.

GNDP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             11
when            k      =       5,       15,       30            in            Data            set-I.            In            Data            set-II,            the            im-                                   dation                      of                      China                      General                      Program                      under                      grant                      No.
provements                     of                     GNDP                     are                     5:24%,2:23%,1:34%                     for                                                                      61672420,            the            Key            Project            of            Natural            Science            Founda-
code-level                            accuracy                             and                            2:89%,2:17%,0:88%                            for                                                            tion          of          China          under          grant          No.          61532015,          the          Project          of
visit-level                      precision                      for                      k      =       5,       15,       30                      when                      compared                                 China                             Knowledge                             Center                             for                             Engineering                             Science
with         CAMP_.         It         is         worth         noticing         that         the         performance                                                                                                 and           Technology,           National           Natural           Science           Foundation
gap              between              CAMP_              and              KAME              is              small.              This              is              be-                                                 of                     China                    Innovation                     Research                    Team                     No.                    61721002,
cause           CAMP_           and           KAME           utilize           the           knowledge           infor-                                                                                               Innovation                  Research                  Team                  of                  Ministry                  of                  Education
mation            in            a            similar            approach.            We            conduct            another            set                                                                          (IRT_17R86).
of                    comparative                    experiments                    under                    the                    split                    ratio                    of
0:60           :            0:10           :            0:30              with              the              most              competitive              baselines.                                                    References
As          shown          in          Table          5,          GNDP          still          has          a          superior          perfor-                                                                         1.               Jensen      PB,      Jensen      LJ,      Brunak      S.      Mining      electronic      health      records:      Towards
mance                          than                          other                          baselines.                          Besides,                          although                          the                          better         research         applications         and         clinical         care.         Nat         Rev         Genet.         2012;13:
code-level               accuracy               and               visit-level               precision               of               all               the                                                                       395–405.
                                                                                                                                                                                                                         2.               Choi         E,         Bahadori         MT,         Sun         J.         Doctor         AI:         Predicting         clinical         events         via         re-
knowledge-guided               models               drop               a               little               when               decreas-                                                                                          current         neural         networks.         CoRR,         abs/1511.05942,         2015.
ing                 the                size                 of                the                 training                set,                the                 performances                 are                       3.               Kho         AN,         Geoffrey         Hayes         M,         Rasmussentorvik         L,         et         al.         Use         of         diverse
                                                                                                                                                                                                                                 electronic         medical         record         systems         to         identify         genetic         risk         for         type         2
still         better         than         the         models         without         domain         knowledge,                                                                                                                   diabetes         within         a         genome-wide         association         study.         J         Am         Med         Inform
as             shown             in             Table             4.                                                                                                                                                             Assoc         2012;19:212–218.
                                                                                                                                                                                                                         4.               Caruana         R,         Lou         Y,         Gehrke         J,         et         al.         Intelligible         models         for         healthcare:         Pre-
         These            results            demonstrate            that            because            of            the            better                                                                                       dicting         pneumonia         risk         and         hospital         30-day         readmission.         In:         Proceed-
utilization         of         the          medical          knowledge         graph         and         reason-                                                                                                                 ings        of        the        21th        ACM        SIGKDD        International        Conference        on        Knowledge
able                      model                      conﬁguration,                      the                      proposed                      GNDP                      can                                                     Discovery      and      Data      Mining,      Sydney,      NSW,      Australia,      August      10–13,      2015
                                                                                                                                                                                                                                 pp.         1721–1730.
generate                  more                  accurate                  predictions                  than                  the                  existing                                                               5.               Ren         S,         He         K,         Girshick         RB,         Sun         J.         Faster         R-CNN:         Towards         real-time         object
knowledge-guided             models.                                                                                                                                                                                             detection         with         region         proposal         networks.         CoRR,         abs/1506.01497,
                                                                                                                                                                                                                                 2015.
                                                                                                                                                                                                                         6.               Devlin         J,         Chang         M-W,         Lee         K,         Toutanova         K.         BERT:         Pre-training         of         deep         bi-
                                                                                                                                                                                                                                 directional         transformers         for         language         understanding.         CoRR,
Conclusions                                                                                                                                                                                                                      abs/1810.04805,         2018.
In                   this                   study,                   we                   propose                   GNDP,                   a                   novel                   diagnosis                        7.               Shickel         B,         Tighe         P,         Bihorac         A,         Rashidi         P.         Deep         EHR:         A         survey         of         recent
                                                                                                                                                                                                                                 advances      in      deep      learning      techniques      for      electronic      health      record      (EHR)
prediction                   method                   to                   predict                   patients’                   future                    health                                                                analysis.         IEEE         J         Biomed         Health         Inform         2018;22:1589–1604.
status         based         on         their         historical         medical         records.         Taking                                                                                                         8.               Choi         E,         Bahadori         MT,         Schuetz         A,         et         al.         RETAIN:         Interpretable         predictive
                                                                                                                                                                                                                                 model         in         healthcare         using         reverse         time         attention         mechanism.         CoRR,
advantage          of          GNNs,          GNDP          learns          the          spatial          and          tem-                                                                                                      abs/1608.05745,         2016.
poral            patterns             from            patients’            sequential            graph             data,            in                                                                                   9.               Choi       E,      Xiao      C,      Stewart       WF,      Sun      J.      Mime:      Multilevel      medical      embedding      of
which               the               knowledge               from               the               medical               ontology               and                                                                              electronic         health         records         for         predictive         healthcare.         CoRR,
                                                                                                                                                                                                                                 abs/1810.09593,         2018.
the                   information                  from                  EHR                  are                  naturally                  infused.                  In                                            10.               Ma       F,       Chitta       R,       Zhou       J,       et       al.       Dipole:       Diagnosis       prediction       in      healthcare       via
this                   way,                   GNDP                   can                   fully                   make                   use                   of                   the                   medical               attention-based         bidirectional         recurrent         neural         networks.         CoRR,
                                                                                                                                                                                                                                 abs/1706.05764,         2017.
knowledge              as              an              internal              information              of              EHR              data             to                                                            11.             Ma        F,        You        Q,        Xiao        H,        et        al.        KAME:        Knowledge-based        attention        model
improve               prediction               accuracy.               We               experimentally               ver-                                                                                                        for        diagnosis        prediction        in        healthcare.        In:        Proceedings        of        the        27th
                                                                                                                                                                                                                                 ACM        International        Conference        on        Information        and        Knowledge
ify                    the                     necessity                    of                    the                     model                    components                     through                                        Management,        CIKM        2018,        Torino,        Italy,        October        22–26,        2018.
ablation                  experiments                   and                         compare                   our                   model                   with                                                                 pp.       743–752.
                                                                                                                                                                                                                      12.             Choi        E,        Bahadori        MT,        Song        L,        et        al.        GRAM:        Graph-based        attention
SOTA                approaches                on                two                real-world                EHR                data                sets                                                                         model       for       healthcare       representation       learning.       CoRR,       abs/1611.07012,
in                      diagnosis                      prediction                      tasks.                      Experimental                      results                                                                     2016.
conﬁrm                 that                 GNDP                 signiﬁcantly                 outperforms                  RNN                                                                                        13.               Gao        J,         Wang         X,        Wang         Y,         et        al.         CAMP:        Co-attention        memory         networks         for
                                                                                                                                                                                                                                 diagnosis         prediction         in         healthcare.         In:         2019         IEEE         International         Confer-
and                 attention-based,                 knowledge-guided                 clinical                 pre-                                                                                                              ence       on       Data       Mining,       ICDM       2019,       Beijing,       China,       November       8–11,       2019.
diction            models.                                                                                                                                                                                                       pp.         1036–1041.
                                                                                                                                                                                                                      14.               Yan        S,        Xiong        Y,        Lin        D.        Spatial        temporal        graph        convolutional        networks        for
                                                                                                                                                                                                                                 skeleton-based         action         recognition.         CoRR,         abs/1801.07455,         2018.
                                                                                                                                                                                                                      15.               Birkhead         GS,         Klompas         M,         Shah         NR.         Uses         of         electronic         health         records         for
Author           Disclosure           Statement                                                                                                                                                                                  public         health         surveillance         to         advance         public         health.         Ann         Rev         Public
No             competing             ﬁnancial             interests             exist.                                                                                                                                           Health         2015;36:345–359.
                                                                                                                                                                                                                      16.               Yao       L,       Mao        C,        Luo        Y.       Graph        convolutional        networks       for        text        classiﬁcation.
                                                                                                                                                                                                                                 CoRR,         abs/1809.05679,         2018.
Funding           Information                                                                                                                                                                                         17.               Zhou      J,      Cui      G,      Zhang      Z,      et      al.      Graph      neural      networks:      A      review      of      methods
                                                                                                                                                                                                                                 and         applications.         CoRR,         abs/1812.08434,         2018.
This         work         was         supported         by         the         National         Key         Research                                                                                                  18.               Velickovic         P,         Cucurull         P,         Casanova         A,         et         al.         Graph         attention         networks.
and              Development              Program              of              China              under              grant              No.                                                                                      ArXiv,         abs/1710.10903,         2017.
                                                                                                                                                                                                                      19.               Kipf         TN,         Welling         M.         Semi-supervised         classiﬁcation         with         graph         convolu-
2018YFC130078,                the                National                Natural                Science                Foun-                                                                                                     tional         networks.         CoRR,         abs/1609.02907,         2016.

12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               LI           ET           AL.
20.               Chen         L,         Zhang         H,         Xiao         J,         et         al.         SCA-CNN:         Spatial         and         channel-wise         at-
              tention         in         convolutional         networks         for         image         captioning.         CoRR,                                                                                                                                                                                                                                                   Abbreviations           Used
              abs/1611.05594,         2016.                                                                                                                                                                                                                                                                                            2D        ¼          two-dimensional
21.               Zhang       X,       Qian       B,       Li       X,       et       al.       An       interpretable       fast       model       for       predicting       the                                                                                                                                         CAMP        ¼          co-attention          memory          networks          for          diagnosis
              risk         of         heart         failure.         In:         Proceedings         of         the         2019         SIAM         International                                                                                                                                                                                                     prediction
              Conference         on         Data         Mining,         SDM         2019,         Calgary,         Alberta,         Canada,         May                                                                                                                                                                           CCS        ¼          Clinical          Classiﬁcations          Software
              2–4,         2019.         pp.         576–584.                                                                                                                                                                                                                                                                     EHR        ¼          electronic          health          record
22.               Zhang         Z,         Cui         P,         Zhu         W.         Deep         learning         on         graphs:         A         survey.         CoRR,                                                                                                                                          GNDP        ¼          Graph          Neural          Network-Based          Diagnosis          Prediction
              abs/1812.04202,         2018.                                                                                                                                                                                                                                                                                 GNNs        ¼          graph          neural          networks
23.               Cho         K,         van         Merrienboer         B,         Gu¨   lçehre         Cx,         et         al.         Learning         phrase         represen-                                                                                                                                      GRAM        ¼          graph-based          attention          model
              tations         using         RNN         encoder-decoder         for         statistical         machine         translation.                                                                                                                                                                                     GRU        ¼          Gated          Recurrent          Unit
              CoRR,         abs/1406.1078,         2014.                                                                                                                                                                                                                                                                            ICD        ¼          International          Classiﬁcation          of          Diseases
                                                                                                                                                                                                                                                                                                                            KAME        ¼          knowledge-based          attention          model
                                                                                                                                                                                                                                                                                                                       RETAIN        ¼          reverse          time          attention          mechanism
       Cite        this        article        as:         Li         Y,         Qian         B,         Zhang         X,         Liu         H         (2020)         Graph         neural                                                                                                                                    RNNs        ¼          recurrent          neural          networks
       network-based      diagnosis       prediction.       Big       Data       8:X,      1–12,       DOI:       10.1089/                                                                                                                                                                                                   SOTA        ¼          state-of-the-art
       big.2020.0070.                                                                                                                                                                                                                                                                                                 ST-GCN        ¼          spatial-temporal          graph          convolutional          network

