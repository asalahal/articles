Li et al.
BMC Medical Informatics and Decision Making  2021,21(Suppl7):368
https://doi.org/10.1186/s12911-021-01733-1
  RESEARCH                                                                                                                                                                                     Open Access
Document-level medical relation ex trac tion
via edge   -  oriented graph neural net work based
on document struc ture and ex ternal k nowledge
TaoLi                                                            1, Ying                                                                                        Xiong1,   XiaolongWang                                                                                                                                                                                            1, QingcaiChen                                                                                                                                                                                        1,2 and Buzhou                                                                                                                                                                                                                                                          Tang1,2*
Fr o m The 5th International Workshop on Semantics-Powered Data Mining and Analytics (SEPDA
2020) Vir tual. 16-19 December 2020`
   Abstract
   Objective:                                                Relation extraction (RE) is a fundamental task of natural language processing, which always draws plenty
   of attention from researchers, especially RE at the document-level. We aim to explore an effective novel method for
   document-level medical relation extraction.
   Methods:                                                                                                                                                                We propose a novel edge -oriented graph neural network based on document structure and external
   k nowledge for document-level medical RE, called SKEoG. This network has the ability to take full advantage of docu-
   ment structure and external k nowledge.
   Results:                                                                                                                                          We evaluate SKEoG on two public datasets, that is, Chemical-Disease Relation (CDR) dataset and Chemical
   Reactions dataset (CHR) dataset, by comparing it with other state -of-the -ar t methods. SKEoG achieves the highest
   F1-score of 70.7 on the CDR dataset and F1-score of 91.4 on the CHR dataset.
   Conclusion:                                                                                                                                                                                                                       The proposed SKEoG method achieves new state -of-the -ar t per formance. Both document structure
   and external k nowledge can bring per formance improvement in the EoG framework. Selecting proper methods for
   k nowledge node representation is also ver y impor tant.
   Keywords:                                                                      Medical relation extraction, Graph neural network, Document structure, External k nowledge
Background                                                                                                          sentence-level RE, document-level RE is more challeng-
Relation extraction (RE) that extracts relations among                                                              ing as document-level RE needs to consider both intra-
entities in the text is a fundamental task of natural lan-                                                          sentence relations and inter-sentence relations as a
guage processing (NLP). There may be two kinds of RE:                                                               whole, as shown in Fig . 1.
(1) sentence-level RE that extracts relations in the same                                                               In recent years, document-level RE has attracted more
sentence, called intra-sentence relations; (2) document-                                                            and more attention from researchers, and various kinds
level RE that extracts relations in the same sentence                                                               of machine learning methods have been proposed.
and cross sentences, and the relations cross sentences                                                              Among these methods, multi-instance learning (MIL)
are called inter-sentence relations. Compared with                                                                  first introduced by Riedel et al. [1] for document-level RE
                                                                                                                    is one of the most popular. MIL models multiple entity
*Correspondence:  tangbuzhou@gmail.com                                                                              mention pairs of the same two given entities over a docu-
1 Harbin Institute of                                                  Technology, Shenzhen, China                  ment and has the ability to reduce noise in distant super-
Full list of author information is available at the end of the article                                              vised learning [2,                                                                                                                             3]. Although the existing MIL methods
                                                          © The Author(s) 2021. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which
                                                          permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the
                                                          original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or
                                                          other third party material in this article are included in the article’s Creative Commons licence, unless indicated other wise in a credit line
                                                          to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutor y
                                                          regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this
                                                          licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/. The Creative Commons Public Domain Dedication waiver (http:// creat iveco
                                                          mmons. org/ publi cdoma in/ zero/1. 0/) applies to the data made available in this article, unless other wise stated in a credit line to the data.

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                    Page 2 of 9
  Fig.1                                                 Example of document-level relation extraction
achieve considerable results, they also have some disad-                       proposed SKEoG model achieves new state-of-the-art
vantages. One disadvantage of these methods is that all                        performance, outperforming KEoG.
entity pairs are considered individually and the implicit
correlations among entities in different pairs in a docu-                      Related work
ment are ignored.                                                              The studies most related to our work are EoG [10] and
  Graph neural networks (GNNs) that can represent                              KEoG [11]. EoG is the first edge-oriented GNN for doc                                                                                                                                               -
the whole document and consider implicit correlations                          ument-level RE proposed by Christopoulou et  al. [10]. In
among entities in different pairs have shown great poten-                      EoG, information at different levels, including mention,
tial for document-level RE [4–10]. They may fall into                          entity and sentence, are regarded as nodes connected
two categories: (1) node-oriented GNNs [4–9]; (2) edge-                        by five types of edges. EoG models document-level rela-
oriented GNNs (denoted by EoG) [10]. Node-oriented                             tions between entities directly and achieves much bet-
GNNs mainly focus on node representation, while edge-                          ter results than node-oriented GNNs [10]. KEoG is an
oriented GNNs mainly focus on edge representation. As                          extension of EoG by introducing two new types of nodes
a relation between two entities is an instinctive edge in                      regarding the document itself and knowledge concept
GNNs, edge-oriented GNNs outperformed node-ori-                                and two new types of edges to connect the two new types
ented GNNs on document-level RE in some studies [10,                           of nodes. KEoG shows much better performance than
11]. In the case of EoG, document structure and external                       EoG [11].
knowledge have been proved meaningful. However, there                            Inspired by KEoG [11], we propose a novel EoG that
is no study to investigate them comprehensively.                               considers document structure and external knowledge
  In this study, based on the backbone of EoG, we pro-                         comprehensively, that is SKEoG. Based on KEoG, SKEoG
pose a novel GNN to consider document structure and                            further introduces two new types of nodes, one regard-
external knowledge for document-level RE comprehen-                            ing document structure and the other regarding external
sively, called SKEoG, which is an extension of KEoG pro-                       knowledge such as entity description. In this study, we
posed in our previous study [11]. To evaluate SKEoG, we                        use three models, that is, TransE [12], RESCAL [13] and
conduct experiments on two public medical datasets.                            GAT [14] to represent knowledge node based on knowl                                                       -
Experiment results show that both document struc-                              edge graph respectively, and use two models, that is
ture and external knowledge are beneficial to documen-                         Doc2vec [15] and an end-to-end neural network , to rep                                                                                      -
tal-level medical RE in the backbone of EoG, and the                           resent knowledge node based on entity description.

Li et al. BMC Medical Informatics and Decision Making  2021, 21(Suppl 7):368                                                                                                                                                                                                                                                                                                      Page 3 of 9
     Fig. 2           Example of document structure
Methods                                                                                                                                                                                                             •                                                                                              Sentence No de (S). E ach sentence no de [()]             s is repre                                                                                                                       -
In this section, we first introduce RE based on docu               -                                                                                                                                                          sented as                            ns           =        avgwi  ∈           s                      )        ;          ts ,                                                                      where ts is an
ment structure, and then RE based on external knowl                   -                                                                                                                                                       embedding to represent the node type of sentence.
edge from two aspects: knowledge graph and entity                                                                                                                                                                   •                                                                       Chapter Node (C ). A chapter node                                                                                                                                                                                                                                                                                                                                                                                                          c is represented
description.                                                                                                                                                                                                                  by the average representation of all sentence nodes it
                                                                                                                                                                                                                              contains and the embedding of the node type of [                                               (                         )              ]
                                                                                                                                                                                                                              chapter, that is , n                                                       avgs∈           c                 )                ;          tc;
Relation extraction based on document structure                                                                                                                                                                                                                                        c           =
A document usually has a hierarchical structure like an                                                                                                                                                             •                 Document Node (D). A document node d is repre                                                          -
example, as shown in Fig.             2, where a document                                                                                                               d1 co n                                        -      sented by the average representation of all chapter
sists of two chapters                                                       c1 and                   c2   , and each chapter con                                                                                                                                                                                                                            -no des and the emb e dding of the no de ty p e of do cu                                                                                                                                                                                                                                                                                                                 -
tains some sentences with many entity mentions.                                                                                                                                                                               ment               nd            =                                        [avgc∈          d    (       nc   )      ;         td    ].
Supp  o s e that a s entence                                                           s          =                             w1 w2      ...               w|s|   , it can be rep                                                                                                               -
resented as                                        Hs                                                              =localhlocal1                                                          ,      hlocal2                                                          ,     ...                   ,      hlocal|s| via an
encoding layer.
      In a document with |       d| sentences d            =                                  s1,       s                                                           s ...                   ,       s|d | ,
there are five kinds of nodes corresponding to docu                   -
ment structure as follows:
      •                         Mention Node (M). Each mention node [                                         (                      )                ]     m is repre              -
                sented as                                  nm          =           avgwi  ∈          m                          )        ;         tm   , where ‘;’
                denotes concatenation operation, and                                                                                                             tm is an
                emb e dding to represent the no de ty p e of mention
                node.
      •                Entity Node (E). An entity                                                                         e is represented as
                ne           =                                             [avgm∈         e   (       nm  )      ;        te   ]                ,            where avgm∈        e   (      nm  ) is the aver                                                                                                                                                      -
                age re    pre    s    ent    ation of all mentions cor      re    sp         onding to
                e            ,         and te is an embedding to represent the node type
                of entity node.                                                                                                                                                                                    Fig. 3           Graph to represent document structure

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Page 4 of 9
         Given the five kinds of nodes above, we connect them                                                                                                                                                                                                                                                •                             Chapter-Document (CD). There is an edge between a
with the following six kinds of edges, as shown in Fig .                 3:                                                                                                                                                                                                                                                chapter node c and a document node                                                                                                                                           d  , and it is repre                                                                           -
                                                                                                                                                                                                                                                                                                                           sented as                                    eDC             =                                              [nd   ;        nc   ].
         •                    Mention-Sentence (MS). When an entity mention
                       m app ears in a sentence, there is an e dge b etwe en                                                                                                                                                                                                                                 We further apply a linear transformation to all edge rep-
                       the corresponding entity mention node and the                                                                                                                                                                                                                                resentations using the following equation:
                       sentence node                                                                  s    , and the edge is represented as
                       eMS            =                                              [nm ;       ns   ];                                                                                                                                                                                                                   v (       1)z                        =W      z   ez    ,                                                                                                                                                                                       (5)
         •                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Mention-Mention (MM). When two entity mentions where z             ∈                             {    MS    ,     MM    ,     ME    ,     SS    ,     ES    ,     SC      ,     CC      ,     CD} and W       z is
                       m1 and                               m2 appear in the same sentence                                                                                                                             s   , there is an                                                            a learnable parameter matrix.
                       e dge b etwe en the two cor resp onding entity mention
                       nodes                           nm1[              and                     nm2  . 2e edge can be represented as ]                                                                                                                                                             Relation extraction based on external knowledge
                       eMM            =                          nm1;        nm2;        cm1s                                            2;        d  (      s1 ,s2  )                       ,                                                         where d  (     m1 ,m2  )                     To utilize external knowledge, we regard any entity in
                       is the re pre s ent ation of the relative dist ance b  e twe  en                                                                                                                                                                                                             external knowledge that also appears in text as an addi-
                       the two entity mentions in the s entence, and                                                                                                                                                                          cm1 m2 is                                             tional node and connect it to the corresponding entity node
                       the attention ve                 ctor b              e       twe                 en the two entity mentions                                                                                                                                                                  in text. In this paper, we introduce two kinds of knowledge
                       calculated by the following equations:                                                                                                                                                                                                                                       nodes according to the forms of external knowledge of
                                              α                                      T           wi,                                                                                                                                                                  (1)                           entities: (1) entity description and (2) knowledge graph.
                                                     k    ,i            =                      nmk                                                                                                                                                                                                           Suppose that e1        ,                                                           e2 and                              e3 have their external descrip                                                                                                                                                                                                                            -
                                                                                                                           α          k  ,                                                                                                                                                          tion,                    e1 and                             e3 exist in an external knowledge graph, the
                                              ak  ,i              =                                                                                                                                            exp∑(i)()     ,                                        (2)                           g  raph b a  s e   d on do   c ument str  uc ture a  s show  n in Fig      .                                                                                                                                                                                                                                                                                                                                                                                                                         3 c  an
                                                                                          ∈    [1,n       ],j         /∈m k      exp               α          k  ,j
                                                                                                                                                                                                                                                                                                    b e extende d to the graph a s shown in Fig  .                                                                                                                                                                                                                                                                                                                                                  4                    af ter adding
                                                                                                                                                                                                                                                                                                    knowledge nodes, where                                                                                                         kdi and                                   ksj denote knowledge
                                              ai           =             a1,i        +a          2,i                                                                                                                                                                  (3)                           node based on entity description and knowledge node
                                                                                      2                                                              ,
                                                                                                                                                                                                                                                                                                    based on knowledge graph, respectively. In this way, we can
                                              cm1  ,                                                                                                                                                                                                                  (4)                           obtain a g raph that take s f  ull adv antage of exter nal knowl                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -
                                                              m        2         =                    H   T    a,                                                                                                                                                                                   edge as much as possible.
                       where                              k               ∈                             {      1,       2}         , ai is the attention weight of the                                                                                                                              Knowledge node representation based on knowledge
                       ith word in the entity mention pair <                                                                                                                                                       m1  ,   m2>, and
                       H             ∈                      Rhidden_                                                                               dim×             |s| is the representation of sentence                                                                                           graph
                       s;                                                                                                                                                                                                                                                                           We deploy a translation distance model, a semantic match-
         •                                                                      Entity-Mention (ME). sere is an edge between an                                                                                                                                                                     ing model and a graph model, that is , TransE [12], RESC AL
                       entity mention no  de                                                                                m and the corresponding entity                                                                                                                                          [13] and GAT [14], to represent knowledge nodes based on
                       node                      e  , that is ,                               eME            =                                              [nm ;       ne   ];                                                                                                                     knowledge graph respectively.                                                                                                                              ⟨                             ⟩
         •                                                                           Sentence-Sentence (SS). For all sentence nodes in a                                                                                                                                                                     TransE assumes that any triple h,                                 r     ,       t                                                                                                   ,                                                                               where h i s a he  ad
                       do             cument                   , there are e               dge      s b             e      twe               en any two s      entence                                                                                                                              entity no de,                                               r is a relation, and                                                                        t is a tail entity node, sat                                                                                                                                                                                                                                                                                                                                                                    -
                       nodes. An SS edge is represented by [                                            (                        )          ⏐                                            ⏐]                                                                                                         is es the hy p othesis of                                                                                       h     +                             r        ≈                               t  , so as to ensure that the
                                                                                                                                            ⏐                                            ⏐                                                                                                          di st  ance b    e  twe     en two entity no    de  s i s clo  s  e to the re  pre  s  en                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -
                       eSS           =                    nSi   ;         nsj   ;         d                  ]⏐,sj                    ;     ⏐nSi          −                                nsj⏐   (i                  �=                   j),                                                        where nSitation of the relation b etwe en the two no des  . In this w ay,
                       and                  nSj are the re pre s ent ation of                                                                                                        si and the represen                                                                                                                                                                                                                                                                                                                                                                                                         -the multi-hop relation b etwe en two entities can b e repre                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -
                       tation of                                     sj             ,                    and d  (si,sj   ) is the representation of the                                                                                                                                             sente d by additive transitiv ity, that is  , if there is a relation
                       relative distance between si and                                                                                                                                sj measured by the                                                                                          r1 b   e twe   en                                     h1 and                          t1  , a relation                                            r2 between                                            t1 and                        t2  , …, and
                       number of sentences between them;                                                                                                                                                                                                                                            a rel ation                                   rK between                                               tK  −1                and                   tK  , there is an implicit rela                                                                                                                                                                          -
         •                                                                                   Entity-Sentence (ES). When there is an entity men                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -tion between h1 and tK as follows:
                       tion node                                          m corresponding to an entity node                                                                                                                                             e in a
                       sentence                                    s   , there is an edge between                                                                                                  e and                       s   . se edge                                                                               h1        +                            r1        +                            r2     + ··· +                                                   rK             ≈                              tK       ,                                        (6)
                       is represented as                                                                eES            =                                              [ne  ;         ns   ];                                                                                                                 te ma           x-marg        in f         unc    tion of ne    g    ative sampling i   s u   s    e          d a         s
         •                                                                                     Sentence-Chapter (SC ). [ere is an e dge betwe en a                                                                                                                                                  the objective function of TransE:
                       s  entence no     de                                                   s and a chapter node                                                                                 c   , and it is repre                                                                                                                                                                         -  (                                                                                                                                                            ),0)
                       sented as                                     eSC             =                                              [ns  ;         nc    ];                                                                                                                                                                 L        =                                                 ∑                                                                               ,                           t  )         +                         γ                  −                          fr ′ (h′,      t′,
         •                                                                          Chapter-Chapter (CC ). [ere is an edge between two                                                                                                                                                                                                           (   h,r                                ,t        )  ∈�(   h′,rr,tr)  ∈�      �        max(fr   (    h
                       chapter no  de s                                                      c1 and [                         c2 in a document, and it is rep                                                                                                                                                                                                                                                    -]                                                                                                                                                       (7)
                       resented as                                            eCC                  =                nc1;         nc2                      ;

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                                                                                                                                                                                                                                                                                                                                                        Page 5 of 9
      Fig.4                                                 Graph based on document structure and external knowledge
where (     h,                                 r     ,       t  )            ∈                      � is a true triplet , while                                                        (h′,       r′,       t′   )               ∈                /Delta1′                  In addition, we also represent the knowledge node                                                                                                                                                                                   ks
is a negative triplet obtained by sampling,                                                                                                                                                   fr     (         h,                                    t   ) is the  by the sub   g       raph centere         d on the no         de u   sing GAT.
s    core of                       (        h,                                 r     ,       t   )           ,           and γ>                                   0 denote     s the marg        in u    su    ally s    e    t                                             Based on knowledge graph, a node                                                                                                                                                    ks is repre                                                                                    -
to 1. Finally, the le arne d                                                                                h is regarded as                                                        hks  , the knowl                                                                                              -sented by        nks           =                                              [hks  ;          tks   ]            ,                        where hks is the representa                                                                                                                                                  -
e          dge no         de re    pre     s    ent    ation cor     re     sp         onding to no         de                                                                                                     ks w            i    th                                                            -tion obtained from TransE , RESC AL or GAT, and                                                                                                                                                         tks
out considering its type.                                                                                                                                                                                                                                          is the emb e dding of the no de ty p e of knowle dge g raph
        RESC AL captures the p otential semantics b etwe en two                                                                                                                                                                                                    no de. te e dge b etwe en an entity no de                                                                                                                                             e and the cor                                                                                                                                                           -
entities through the bilinear function as follows :                                                                                                                                                                                                                responding knowledge node                                                                                                                       k   s is represented as
                       fr     (       h,                          t   )           =                         hT     Mr   t     ,                                                                                                          (8)                       eEKS            =                                              [ne  ;         nks   ] , and it is also f ur ther transforme d into
                                                                                                                                                                                                                                                                   v (     1)EKS via a linear transformation function:
        As shown in Fig  .s                                                                                                                                                                                 5                      , RESC AL represents relation triples
a s a thre e-dimensional tensor                                                                         ⟨                       X      ,         where                    Xijk         =                          1 indicates
that there i      s a tr                ue tr           iple        t                                        ei,        rk,        ej   ⟩. The tensor decomposi-
tion model is used to model the relationship implicitly :
                    Xk         ≈                    ARk   AT       ,                      for               k        =                                 1,     ...                    ,     m,                                            (9)
where Xk is the                                                       k  th component of                                                               X      ,       A       ∈                   Rn×r        contains
the potential representations of entities ,                                                                                                                                           Rk          ∈                      Rr ×r   is a
symmetric matrix used to model the potential interac                                                                                                                                                                                                                                                                                                                                                                                                                                                       -
tions in the                                      k         th         relation:
                       f           (        A,                                    Rk     )           =                                     1∑AXijk        −                     aT2  ,
                                                                        2      i,j         ,k                                        i                 Rk   aj  )                                                                  (10)
where                        hks is the comp onent of                                                                                   A corresponding to node
ks.                                                                                                                                                                                                                                                                       Fig.5                                                 Three-dimensional tensor used to represent relation triple in
                                                                                                                                                                                                                                                                          RESCAL

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                                                                                                                                                                               Page 6 of 9
    Fig.6                                                 The end-to-end neural network used to represent the description of a given knowledge node
             v (       1)EKS=             WEKSeEKS    ,                                                                                          (11)                length l (p           ath b                         e           twe                           en i and j    , and path betwe en         j and          k         )
                                                                                                                                                                     to generate one long path of length                                                              2l   .
where W     EKS is a learnable parameter matrix.                                                                                                                           All p aths f  rom no    de                               i to node                 k are aggregated to form
                                                                                                                                                                     the representation of the e dge from no de                                                                            i to node                    j of
Knowledge node representation based on description                                                                                                                   length             2l    as follows :
In this paper, we use the following two methods to obtain                                                                                                                             (     2l )                                                                (                       )
knowledge node representation based on the entity                                                                                                                                 vij                            =                             α                      v (      l )ij                 +                           (       1     −                           α                 )                ∑fv (      l )ik               ,         v (      l )kj,(14)
description:                                                                                                                                                                                                                                     k �=i,j
     1.                                        Doc2vec [15] (also called paragraph2vec), inspired by                                                                 where              α                  ∈                              [0,        1] is a line ar inter p  olation sc alar to control
             word2vec [16] proposed by Tomas Mikolov, which                                                                                                          the contribution of edges of length                                                             l.
             can transform a sentence or a short text into a cor-                                                                                                          After obtaining the path representation of any entity
             responding low dimensional vector representation of                                                                                                     pair of interest  , we adopt the sof tma  x f unction a s cla ssi                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -
             fixed length.                                                                                                                                            er. Like in K EoG , b oth cross -entropy loss f unction and
     2.                     An end-to-end neural network, as shown in Fig.       6,                                                                                  soft F-measure loss function are used as a part of the
             which are used to encode the description text of a                                                                                                      total loss function.
             given knowledge node, called E MB.                                                                                                                      Experiments
     Similar to knowledge node ks   , knowledge node                                                                                                 kd              Datasets
based on description is represented as                                                                          nkd            =                                              [hkd   ;         tkd     ]            . We conduct all experiments on the following two
[e e  dge b etwe  en                               kd and the corresponding entity node                                                                              datasets:
e i   s re   pre    s   ente         d a       s   eEKD           =                                              [ne  ;        nEKD   ] and is further trans                                                                                                                                                                                                                                                                                                                                           -•                                        Chemical-Disease Relation (CDR) dataset is a dataset
formed by                                                                                                                                                                          for document-level chemical-induced disease (CID)
             v (       1)   =             WEKDeEKD   ,                                                                                           (12)                              relation extraction, which is provided for the Bio-
                EKD                                                                                                                                                                Creative V challenge [18]. It contains a training set of
where            W    EKD is a learnable parameter matrix.                                                                                                                         500 abstracts, a development set of 500 abstracts and
                                                                                                                                                                                   a test set of 500 abstracts from PubMed.
Inference                                                                                                                                                                  •                      Chemical Reactions dataset (CHR) dataset [9] is a
Following KEoG, with the help of the walk aggregation                                                                                                                              dataset provided by the national text mining center
layer [17], a path between two entity nodes                                                                                    i and            k of                               (NaCTeM) of the school of computer science, Uni-
length            2l     can be represented as                                                                                                                                     versity of Manchester. It contains 12,094 PubMed
                 (                        )                (                   (                    ))                                                                             abstracts with their titles. Following Li et  al. [11], we
              f      )(       l )              =                              σv (       l )W         v (       l ),                             (13)                              split the CHR dataset into a training set of 7,298 Pub-
                        ik                           ,         v (       l )kjik             ⊙kj                                                                                   Med abstracts, a development set of 1,182 PubMed
where             σ    is the sig moid activation f unction,                                                             ⊙     is the ele                       -                  abstracts and a test set of 3,614 PubMed abstracts .
ment- w ise multiplic ation, and                                                    W            ∈               Rdz×d                  z is a learnable
parameter matrix used to combine two short paths of

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Page 7 of 9
Table1                                                                                                                          Statistics of the CDR and CHR datasets
Dataset                                                                                                                                               CDR                                                                                                                                                                                                                                                                                                                                                                                                                                                                 CHR
                                                                                                                                                      #doc                                                                                                                                                                                         #positive                                                                                                                                                                                         #negative                                                                                                                                                                                            #doc                                                                                                                                                                                         #positive                                                                                                                                                                                                                             #negative
Train                                                                                                                                                                                                                                                                    500                                                                                                                                                                                                                                      1038/284                                                                                                                                                                                                                  4202/2746                                                                                                                                                                                                                 7298                                                                                                                                                                                                                    19,644/6438                                                                                                                                                                                                                 33,860/20816
Dev                                                                                                                                                                                                                                                                                500                                                                                                                                                                                                                                      1012/246                                                                                                                                                                                                                  4075/2478                                                                                                                                                                                                                 1182                                                                                                                                                                                                                    3186/1051                                                                                                                                                                                                                                         5535/3425
Test                                                                                                                                                                                                                                                                                 500                                                                                                                                                                                                                                      1066/319                                                                                                                                                                                                                  4138/2593                                                                                                                                                                                                                 3614                                                                                                                                                                                                                    9578/2962                                                                                                                                                                                                                                         16,151/9708
Table2                                                                                                                          Comparison results of SEoG and other different methods on the CDR and CHR test sets (%)
Dataset                                                                                                                                                                                                                                                Method                                                                                                                                                                            Overall                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Intra                                                                                                                                                                                                                                                Inter
                                                                                                                                                                                                                                                                                                                                                                                                                                         P                                                                                                                                                                                                                                                   R                                                                                                                                                                                                                                                   F1                                                                                                                                                                                                                                                   F1                                                                                                                                                                                                                                                          F1
CDR                                                                                                                                                                                                                                                                                             Gu etal. [3]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          55.7                                                                                                                                                                                                                                          68.1                                                                                                                                                                                                                                          61.3                                                                                                                                                                                                                                          57.2                                                                                                                                                                                                                                                  11.7
                                                                                                                                                              Verga etal. [20]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             55.6                                                                                                                                                                                                                                          70.8                                                                                                                                                                                                                                          62.1                                                                                                                                                                                                                                          –                                                                                                                                                                                                                                                                                                     –
                                                                                                                                                              Nguyen and Verspoor [5]                                                                                                                                                                                                                                                                                                                                                                                      57.0                                                                                                                                                                                                                                          68.6                                                                                                                                                                                                                                          62.3                                                                                                                                                                                                                                          –                                                                                                                                                                                                                                                                                                     –
                                                                                                                                                              Sahu etal. [9]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          52.8                                                                                                                                                                                                                                          66.0                                                                                                                                                                                                                                          58.6                                                                                                                                                                                                                                          –                                                                                                                                                                                                                                                                                                     –
                                                                                                                                                              Christopoulou etal. [10]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       62.1                                                                                                                                                                                                                                          65.2                                                                                                                                                                                                                                          63.6                                                                                                                                                                                                                                          68.2                                                                                                                                                                                                                                                  50.9
                                                                                                                                                              KEoG (node) [11]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               65.4                                                                                                                                                                                                                                   71.2                                                                                                                                                                                                                                          68.2                                                                                                                                                                                                                                          71.8                                                                                                                                                                                                                                                  58.3
                                                                                                                                                              SEoG                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                64.5                                                                                                                                                                                                                                                        75.5                                                                                                                                                                                                                                                69.6                                                                                                                                                                                                                                                73.4                                                                                                                                                                                                                                                        59.9
CHR                                                                                                                                                                                                                                                                                              CNN-RE [9]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  81.2                                                                                                                                                                                                                                          87.3                                                                                                                                                                                                                                          84.1                                                                                                                                                                                                                                          –                                                                                                                                                                                                                                                                                                     –
                                                                                                                                                              RNN-RE [9]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  83.0                                                                                                                                                                                                                                          90.1                                                                                                                                                                                                                                          86.4                                                                                                                                                                                                                                          –                                                                                                                                                                                                                                                                                                     –
                                                                                                                                                              Sahu etal. [9]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          84.7                                                                                                                                                                                                                                          90.5                                                                                                                                                                                                                                          87.5                                                                                                                                                                                                                                                        –                                                                                                                                                                                                                                                                                                                       –
                                                                                                                                                              KEoG (node) [11]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               89.9                                                                                                                                                                                                                                                92.6                                                                                                                                                                                                                                                91.2                                                                                                                                                                                                                                                93.4                                                                                                                                                                                                                                                        86.3
                                                                                                                                                              SEoG                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                88.3                                                                                                                                                                                                                                          92.6                                                                                                                                                                                                                                          90.4                                                                                                                                                                                                                                          93.1                                                                                                                                                                                                                                                  84.4
Bold highlight the highest result on a given dataset in our experiments
                In this paper, MeSH1 and Biochem4j2 are used as the                                                                                                                                                                                                                                                                                                                                                                                                                                                                               We start with EoG that only considers document
external knowledge of the CDR dataset and CHR dataset,                                                                                                                                                                                                                                                                                                                                                                                                                                                                            structure, called SEoG, then investigate EoG that con-
respectively.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     siders both document structure and external knowl-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  edge, i.e., SKEoG, and finally compare them with other
Experimental settings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             state-of-the-art methods. For convenience, we use
Following our previous work , we first train all models on                                                                                                                                                                                                                                                                                                                                                                                                                                                                        “SKEoG(KG                       +                              KD)”, such as “SKEoG(TransE                                                                           +Do c2ve c)”,
the training set, select the best hyper-parameters on the                                                                                                                                                                                                                                                                                                                                                                                                                                                                         to denote the SKEoG model using “KG” to obtain knowl           -
development set, then use the same hyper-parameters                                                                                                                                                                                                                                                                                                                                                                                                                                                                               edge node representation based on knowledge graph and
retrain on the combined set of the training set and devel-                                                                                                                                                                                                                                                                                                                                                                                                                                                                        “KD” to obtain knowledge node representation based on
opment set, and finally report the results on the test set.                                                                                                                                                                                                                                                                                                                                                                                                                                                                       entity description. All word embeddings are initialized by
                For the CDR dataset, hypernym filtering is also used                                                                                                                                                                                                                                                                                                                                                                                                                                                              the pre-trained PubMed word embeddings [19]. Preci                                                                                         -
to ensure that only relations between hyponym entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                            sion (P), recall (R) and F1-score (F1) are used as measures
are kept, rather than relations between rough hypernym                                                                                                                                                                                                                                                                                                                                                                                                                                                                            for model performance evaluation.
entities. For the CHR dataset, the entities that are not
in Biochem4j are removed, and the self-relations, whose
head entity and tail entity are same, are removed. The sta-                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Results
tistics of the two datasets are listed in Table 1, where “#*”                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We compare SEoG with other state-of-the-art methods,
denotes the number of ‘*’, the numbers split by ‘/’ are the                                                                                                                                                                                                                                                                                                                                                                                                                                                                       and the results are shown in Table    2. SEoG outperforms
total number of pairs and the number of inter-sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                            all other methods on the CDR and CHR test sets except
pairs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            KEoG(node) on the CHR dataset, which considers knowl-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  edge nodes based on the knowledge graph. To investigate
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  the effect of the document structure presented in this
1                 ftp://                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          paper, we further compare SEoG with its variant that
                     ftp. nlm. nih. gov/ online/ mesh/ 2017/ mesh2 017. nt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 .does not consider chapter node, i.e., KEoG(node) without
2         http:// bioch em4j. org/.

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Page 8 of 9
Table3                                                                                                                          Effect of different knowledge node representations base on knowledge graph on the CDR and CHR test sets (%)
Dataset                                                                                                                                                                                                                                                                       MethodOverall                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Intra                                                                                                                                                                                                                                                                       Inter
                                                                                                                                                                                                                                                        P                                                                                                                                                                                                                                                                      R                                                                                                                                                                                                                                                                      F1                                                                                                                                                                                                                                                                      F1                                                                                                                                                                                                                                                                             F1
CDR                                                                                                                                                                                                                                                                                                                   SEoG                                                                                                                                                                                                                                                                                                                                                                                                                     64.5                                                                                                                                                                                                                                                                75.5                                                                                                                                                                                                                                                                69.6                                                                                                                                                                                                                                                                73.4                                                                                                                                                                                                                                                                       59.9
                                                                                                            SKEoG (  TransE)                                                                                                                                                                                                                                                                        65.7                                                                                                                                                                                                                                                                75.7                                                                                                                                                                                                                                                                               70.4                                                                                                                                                                                                                                                                       74.0                                                                                                                                                                                                                                                                              60.5
                                                                                                            SKEoG (RESCAL)                                                                                                                                                                                                                                                                       67.7                                                                                                                                                                                                                                                        70.4                                                                                                                                                                                                                                                                69.0                                                                                                                                                                                                                                                                73.0                                                                                                                                                                                                                                                                       58.4
                                                                                                            SKEoG (GAT  )                                                                                                                                                                                                                                                                                                          64.7                                                                                                                                                                                                                                                                72.5                                                                                                                                                                                                                                                                68.4                                                                                                                                                                                                                                                                72.6                                                                                                                                                                                                                                                                       57.6
CHR                                                                                                                                                                                                                                                                                                                   SEoG                                                                                                                                                                                                                                                                                                                                                                                                                     88.3                                                                                                                                                                                                                                                                92.6                                                                                                                                                                                                                                                                90.4                                                                                                                                                                                                                                                                93.1                                                                                                                                                                                                                                                                       84.4
                                                                                                            SKEoG (  TransE)                                                                                                                                                                                                                                                                        89.9                                                                                                                                                                                                                                                                91.4                                                                                                                                                                                                                                                                90.6                                                                                                                                                                                                                                                                93.2                                                                                                                                                                                                                                                                       85.0
                                                                                                            SKEoG (RESCAL)                                                                                                                                                                                                                                                                       90.6                                                                                                                                                                                                                                                        92.1                                                                                                                                                                                                                                                                               91.4                                                                                                                                                                                                                                                                       93.6                                                                                                                                                                                                                                                                              86.4
                                                                                                            SKEoG (GAT  )                                                                                                                                                                                                                                                                                                          87.5                                                                                                                                                                                                                                                                               93.6                                                                                                                                                                                                                                                        90.5                                                                                                                                                                                                                                                                93.1                                                                                                                                                                                                                                                                       84.6
Bold highlight the highest result on a given dataset in our experiments
using knowledge nodes. SEoG shows much better per-                                                                                                                                                                                                                                                                                        Table4                                      Effect of different knowledge node representations
formance than that variant (overall F1-score: 69.6 vs 67.9                                                                                                                                                                                                                                                                                base on description on the CDR test sets (%)
on the CDR dataset, 90.4 vs 89.0 on the CHR dataset).                                                                                                                                                                                                                                                                                     Method                                                                                                                             Overall                                                                                                                                                                                                                                                                                                                Intra                                                                      Inter
This result indicates that the introduced chapter node is                                                                                                                                                                                                                                                                                                                                                                                                                    P                                                                                                     R                                                                                                    F1                                                                                                     F1                                                                                                           F1
effective.
                                                                                                                                                                                                                                                                                                                                          SKEoG (  TransE)                                                                                                                                                                                                                                       65.7                                                                         75.7                                                                         70.4                                                                         74.0                                                                                 60.5
                                                                                                                                                                                                                                                                                                                                          SKEoG (  TransE                                                 +Doc2vec)                                                                                                         66.2                                                                  72.2                                                                         69.1                                                                         73.7                                                                                 56.9
Discussion                                                                                                                                                                                                                                                                                                                                SKEoG (  TransE                                                 +EMB)                                                                                                                                                                   65.5                                                                              76.6                                                                      70.7                                                                      74.3                                                                             61.3
To investigate the effect of different knowledge node rep-                                                                                                                                                                                                                                                                                Bold highlight the highest result on a given dataset in our experiments
resentations base on the knowledge graph for SKEoG, we
compare SKEoG using different knowledge node represen-
tations with SEoG and present the results in Table 3. SKEoG                                                                                                                                                                                                                                                                               hurts the performance of SKEoG(TransE). The results
using a specific knowledge node representation can achieve                                                                                                                                                                                                                                                                                indicate that we should be careful to utilize the knowl                       -
better performance than SEoG on both the CDR and CHR                                                                                                                                                                                                                                                                                      edge based on entity description.
datasets . On the CDR dataset, SKEoG(TransE) achieves the
highest F1-score of 70.4, while SKEoG(RESCAL) achieves
the highest F1-score of 91.4 on the CHR dataset. It is a lit-                                                                                                                                                                                                                                                                             Conclusion
tle strange that SKEoG(RESCAL) and SKEoG(GAT) even                                                                                                                                                                                                                                                                                        We extend our previous work KEoG to SKEoG, which
perform worse than SEoG in some cases. These results                                                                                                                                                                                                                                                                                      takes full advantage of both hierarchical document
may be caused by the characteristics of different knowledge                                                                                                                                                                                                                                                                               structure and external knowledge for document-level
graphs used for knowledge node representation. There are                                                                                                                                                                                                                                                                                  medical RE. In this study, we comprehensively inves                    -
only three types of relations in MeSH, and each entity has                                                                                                                                                                                                                                                                                tigate different methods to obtain knowledge node
only one neighbor on average, that is, most of the existing                                                                                                                                                                                                                                                                               representation based on knowledge graph and entity
entities and relations in MeSH can be effectively modeled                                                                                                                                                                                                                                                                                 description. Experimental results on two public data                    -
by TransE, rather than RESCAL and GAT. In Biochem4j,                                                                                                                                                                                                                                                                                      sets show that both document structure and external
there are nine types of relations, and each entity has three                                                                                                                                                                                                                                                                              knowledge are beneficial to medical RE in the EoG
neighbors on average. The one-to-many, and many-to-one                                                                                                                                                                                                                                                                                    framework . In the case of external knowledge, selecting
complex relations in biochem4j cannot be completely mod-                                                                                                                                                                                                                                                                                  proper methods for knowledge node representation is
eled by TransE , but can be modeled well by RESC AL .                                                                                                                                                                                                                                                                                     also ver y important.
          Moreover, we also investigate the effect of differ              -
ent knowledge node representations base on entity
description for SKEoG by comparing SKEoG(TransE)                                                                                                                                                                                                                                                                                          Abbreviations
using different knowledge node representations with                                                                                                                                                                                                                                                                                       RE: Relation extraction; CDR: Chemical-disease relation; CHR: Chemical reac-
SKEoG(TransE) on the CDR dataset. Table                          4 shows                                                                                                                                                                                                                                                                  tions dataset; NLP: Natural language processing; MIL: Multi-instance learning;
                                                                                                                                                                                                                                                                                                                                          GNNs: Graph neural networks; EoG: Edge-oriented GNNs.
the comparison results. We can see that the knowledge
node representation learned by EMB can bring perfor             -                                                                                                                                                                                                                                                                         Acknowledgements
mance improvement by an F1-score of 0.3%. However,                                                                                                                                                                                                                                                                                        Not applicable.
the knowledge node representation learned by Doc2vec

Li et al. BMC Medical Informatics and Decision Making  2021,21(Suppl7):368                                                                                                                                                     Page 9 of 9
About this supplement                                                                                                              embeddings. In: Proceedings of the BioNLP 2018 workshop, Melbourne,
This article has been published as part of BMC Medical Informatics and Deci-                                                       Australia, 2018. p. 129–36.
sion Making Volume 21 Supplement 7 2021:Selected articles from the Fifth                                                     6.                                                         Zeng D, Liu K, Chen Y, Zhao J. Distant super vision for relation extraction
International Workshop on Semantics-Powered Data Mining and Analytics                                                              via piecewise convolutional neural networks. In: Proceedings of the 2015
(SEPDA 2020). The full contents of the supplement are available at https://                                                        conference on empirical methods in natural language processing, Lisbon,
bmcme dinfo rmdec ismak. biome dcent ral. com/ artic les/ suppl ements/ volume-                                                    Portugal, Sept 2015. p. 1753–62. Accessed 16 Oct 2020 [Online].
21- suppl ement-7.                                                                                                           7.                                                         Jiang X, Wang Q, Li P, Wang B. Relation extraction with multi-instance
                                                                                                                                   multi-label convolutional neural networks. In: Proceedings of the 26th
Authors’ contributions                                                                                                             international conference on computational linguistics: technical papers,
TL, YX and BT design the experiments, TL and BT write the manuscript, and TL,                                                      Osaka, Japan, Dec 2016. p. 1471–80. Accessed 16 Oct 2020 [Online].
YX, XW, QC and BT revised the manuscript. All authors read and approved the                                                  8.                                                         Kipf T, Welling M. Semi-super vised classification with graph convolutional
final manuscript.                                                                                                                  networks. Presented at the international conference on learning repre-
                                                                                                                                   sentations, 2017.
Funding                                                                                                                      9.                                                         Sahu SK, Christopoulou F, Miwa M, Ananiadou S. Inter-sentence relation
Publication costs are funded by NSFCs (National Natural Science Foundations                                                        extraction with document-level graph convolutional neural network. In:
of China) (U1813215 and 61876052), National Key Research and Development                                                           Proceedings of the 57th annual meeting of the association for computa-
Program of China (2017YFB0802204), Special Foundation for Technology                                                               tional linguistics, Florence, Italy, 2019. p. 4309–16.
Research Program of Guangdong Province (2015B010131010), Natural Science                                                     10.                                                         Christopoulou F, Miwa M, Ananiadou S. Connecting the dots: document-
Foundation of Guangdong Province (2019A1515011158), Strategic Emerging                                                             level neural relation extraction with edge-oriented graphs. In: Proceed-
Industr y Development Special Funds of Shenzhen (JCYJ20180306172232154)                                                            ings of the 2019 conference on empirical methods in natural language
and Innovation Fund of Harbin Institute of Technology (HIT.NSRIF.2017052).                                                         processing and the 9th international joint conference on natural
All the funders do not play any role in the design of the study, the collection,                                                   language processing, 2019. p. 4927–38.
analysis, and interpretation of data, or in writing of the manuscript.                                                       11.                                                         Li T, Peng W, Chen Q, etal. KEoG: a knowledge-aware edge-oriented
                                                                                                                                   graph neural network for document-level relation extraction. In: 2020
Availability of data and materials                                                                                                 IEEE international conference on bioinformatics and biomedicine (BIBM).
The datasets analyzed during the current study are available in the https://                                                       IEEE, 2020. p. 1740–7.
biocr eative. bioin forma tics. udel. edu/ tasks/ biocr                                                                                                                                                                                                                                                                                   eative- v/ track-3-                             cdr/ (accessed:  12.                                                         Bordes A, Usunier N, Garcia-Duran A, etal. Translating embeddings for
Sep. 17, 2021) website and in the http:// www. nactem. ac. uk/ CHR/ (Sep. 17,                                                      modeling multi-relational data. In: Neural information processing systems
2021) website.                                                                                                                     (NIPS); 2013. p. 1–9.
                                                                                                                             13.                                                         Nickel M, Tresp V, Kriegel H-P. A three-way model for collective learning
Declarations                                                                                                                       on multi-relational data. In: International conference on machine learn-
                                                                                                                                   ing, 2011, vol. 11. p. 809–16.
Ethics approval and consent to participate                                                                                   14.                                                         Velickovic P, Cucurull G, Casanova A, Romero A, Lio P, Bengio Y. Graph
Not applicable.                                                                                                                    attention networks. Presented at the international conference on learn-
                                                                                                                                   ing representations, 2018.
Consent to publication                                                                                                       15.                                                         Le Q, Mikolov T. Distributed representations of sentences and documents.
Not applicable.                                                                                                                    In: Proceedings of the 31st international conference on machine learning,
                                                                                                                                   Beijing, China, 2014, vol. 32. p. II-1188–96.
Competing interests                                                                                                          16.                                                         Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word repre -
The authors declare no competing interests.                                                                                        sentations in vector space, 2013.
                                                                                                                             17.                                                         Christopoulou F, Miwa M, Ananiadou S. A walk-based model on entity
Author details                                                                                                                     graphs for relation extraction. In: Proceedings of the 56th annual meeting
1                                                                                                                                  of the association for computational linguistics, Melbourne, Australia,
 Harbin Institute of                                                  Technology, Shenzhen, China. 2 Peng Cheng Laborator y,       2018. p. 81–8. Accessed 16 Oct 2020.
Shenzhen, China.                                                                                                             18.                                                         Li J, etal. BioCreative V CDR task corpus: a resource for chemical disease
Received: 14 December 2021   Accepted: 21 December 2021                                                                            relation extraction. Database. 2016;2016:2016.
Published: 30 December 2021                                                                                                  19.                                                         Chiu B, Crichton G, Korhonen A, Pyysalo S. How to train good word
                                                                                                                                   embeddings for biomedical NLP. In: Proceedings of the 15th workshop
                                                                                                                                   on biomedical natural language processing, Berlin, Germany, 2016. p.
                                                                                                                                   166–74. https:// doi. org/ 10. 18653/ v1/ W16- 2922.
References                                                                                                                   20.                                                         Verga P, Strubell E, McCallum A. Simultaneously self-attending to all
 1.                                                         Socher R, Huval B, Manning CD, Ng AY. Semantic compositionality        mentions for full-abstract biological relation extraction. In: Proceedings
       through recursive matrix-vector spaces. In: Proceedings of the 2012 joint                                                   of the 2018 conference of the North American chapter of the associa-
       conference on empirical methods in natural language processing and                                                          tion for computational linguistics: human language technologies, vol. 1
       computational natural language learning, Jeju Island, Korea, July 2012. p.                                                  (long papers), New Orleans, Louisiana, 2018. p. 872–84. https:// doi. org/ 10.
       1201–11. Accessed 16 Oct 2020 [Online].                                                                                     18653/ v1/ N18- 1080.
 2.                                                         Zeng D, Liu K, Lai S, Zhou G, Zhao J. Relation classification via convolu-
       tional deep neural network. In: Proceedings of COLING 2014, the 25th                                                 Publisher’s Note
       international conference on computational linguistics: technical papers,                                             Springer Nature remains neutral with regard to jurisdictional claims in pub-
       Dublin, Ireland, Aug 2014. p. 2335–44. Accessed 16 Oct 2020 [Online].                                                lished maps and institutional affiliations.
 3.                                                         Gu J, Sun F, Qian L, Zhou G. Chemical-induced disease relation extraction
       via convolutional neural network. Database. 2017. https:// doi. org/ 10.
       1093/ datab ase/ bax024.
 4.                                                         Verga P, Strubell E, McCallum A. Simultaneously self-attending to all
       mentions for full-abstract biological relation extraction. In: Proceedings of
       the 2018 conference of the North American chapter of the association for
       computational linguistics: human language technologies, New Orleans,
       Louisiana, Jun 2018, vol. 1. p. 872–84. Accessed 26 Oct 2020 [Online].
 5.                                                         Nguyen DQ, Verspoor K. Convolutional neural networks for chemical-
       disease relation extraction are improved with character-based word

